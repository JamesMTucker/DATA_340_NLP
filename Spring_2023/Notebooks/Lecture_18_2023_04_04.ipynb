{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 18: 2023-04-04 Word Embeddings and Sequence Models\n",
    "\n",
    "## Lecture Overview\n",
    "\n",
    "* Word Embeddings (Word2Vec, GLoVe, FastText, and ELMo)\n",
    "* Sequence Models (RNNs, LSTMs, and BiLSTMs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "### Static Word Embeddings\n",
    "\n",
    "1. Lack of contextual representations: Static embeddings assign a single vector representation to each word, which fails to capture the different meanings or senses of a word when used in different contexts.\n",
    "\n",
    "2. Polysemy: Since static embeddings provide a single representation for each word, they cannot differentiate between multiple senses of words (words with multiple meanings). This can lead to misinterpretation and decreased performance in NLP tasks.\n",
    "\n",
    "3. Limited vocabulary and out-of-vocabulary (OOV) words: Static embeddings are generated from a fixed vocabulary. Words not present in the training corpus are treated as out-of-vocabulary words, and the model struggles to provide meaningful representations for them.\n",
    "\n",
    "4. Suboptimal handling of phrases and idiomatic expressions: Static word embeddings often struggle to capture the meanings of phrases or idiomatic expressions, as they are designed to work with individual words rather than multi-word units.\n",
    "\n",
    "5. Static in nature: Once trained, the word embeddings remain static and do not evolve or adapt to new contexts or updates in language use. This can limit their performance in applications that require up-to-date language understanding.\n",
    "\n",
    "6. No explicit morphological information: Static word embeddings do not explicitly account for morphological information, such as prefixes, suffixes, or inflections, which can be important for understanding word meanings.\n",
    "\n",
    "### Dynamic or Contextual Word Embeddings\n",
    "\n",
    "1. ELMo: Embeddings from Language Models\n",
    "2. BERT: Bidirectional Encoder Representations from Transformers\n",
    "3. GPT: Generative Pre-Training\n",
    "\n",
    "\n",
    "## Caveat: Large Language Models BIG-Bench\n",
    "\n",
    "* BIG-Bench: A benchmark for general-purpose language models [REPO](https://github.com/google/BIG-bench)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence data\n",
    "\n",
    "* Sequence data is data that is ordered in some way. For example, a sequence of words in a sentence, a sequence of characters in a word, a sequence of pixels in an image, a sequence of notes in a song, a sequence of frames in a video, and so on.\n",
    "\n",
    "* Unlike Bag-of-Words models, sequence models can take into account the order of the words in a sentence. This makes them ideal for tasks such as machine translation, speech recognition, and text summarization.\n",
    "\n",
    "* We will follow the standard conventions and model sequence data as follows:\n",
    "\n",
    "$$x^{(i)} = (x_1^{(i)}, x_2^{(i)}, \\ldots, x_T^{(i)})$$\n",
    "\n",
    "Where $T$ is the length of the sequence and $x_t^{(i)}$ is the $t^{th}$ element of the $i^{th}$ sequence in the training set.\n",
    "\n",
    "## Different categories of sequence models\n",
    "\n",
    "* one to one - input layer is a single value (vector or scalar), output layer is a single value (vector or scalar). For example, image classification is a one to one model.\n",
    "* one to many - input layer is a single value (vector or scalar), output layer is a sequence. For example, image captioning is a one to many model.\n",
    "* many to one - input layer is a sequence, output layer is a single value (vector or scalar). For example, sentiment analysis is a many to one model.\n",
    "* many to many - input layer is a sequence, output layer is a sequence. For example, machine translation is a many to many model. Some variants of this model depend on the synchronization of the input and output sequences. For example, in video classification, the input and output sequences are synchronized, whereas in machine translation, the input and output sequences are not synchronized.\n",
    "\n",
    "<center><img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\" width=\"800\" height=\"300\"></center>\n",
    "\n",
    "N.B.: a rectangle is a vector and arrows are functions. \n",
    "\n",
    "source: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.load_ipython_extensions([\n  \"nb-mermaid/nb-mermaid\"\n]);\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.load_ipython_extensions([\n",
    "  \"nb-mermaid/nb-mermaid\"\n",
    "]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Architecture\n",
    "\n",
    "### Standard feedforward neural network\n",
    "\n",
    "```mermaid\n",
    "graph BT\n",
    "    i[Input] --> h((Hidden Layer))\n",
    "    h --> o[Output]\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "```mermaid\n",
    "\n",
    "graph BT\n",
    "    i[Input] --> h((Hidden State))\n",
    "    h --> h\n",
    "    h --> o[Output]\n",
    "\n",
    "```\n",
    "\n",
    "Recall that in standard neural network data is processed by passing the inputs to the forward layer (or hidden layer) and then to the output layer. In a recurrent neural network, the hidden layer receives the input and the current time step from the previous step. This allows the network to process the data sequentially."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single and Multiple layer RNNs\n",
    "\n",
    "<center><img src=\"https://github.com/rasbt/machine-learning-book/blob/main/ch15/figures/15_04.png?raw=true\" width=\"800\" height=\"600\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's code out a forward pass of a single layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape:  torch.Size([2, 5])\n",
      "W_hh shape:  torch.Size([2, 2])\n",
      "b_xh shape:  torch.Size([2])\n",
      "b_hh shape:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# code adapted from Rashka, 2020, Deep Learning with PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)\n",
    "\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print('W_xh shape: ', w_xh.shape)\n",
    "print('W_hh shape: ', w_hh.shape)\n",
    "print('b_xh shape: ', b_xh.shape)\n",
    "print('b_hh shape: ', b_hh.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input shape (batch_size, sequence_length, input_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run a forward pass\n",
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 3, 2])\n",
      "hn shape:  torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "## output of the RNN layer\n",
    "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
    "print('output shape: ', output.shape)\n",
    "print('hn shape: ', hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "    Input      : [[1. 1. 1. 1. 1.]]\n",
      "    Hidden     : [[-0.4701929  0.5863904]]\n",
      "    Output     : [[-0.3519801   0.52525216]]\n",
      "    RNN output : [[-0.3519801   0.52525216]]\n",
      "Time step 1 =>\n",
      "    Input      : [[2. 2. 2. 2. 2.]]\n",
      "    Hidden     : [[-0.88883156  1.2364397 ]]\n",
      "    Output     : [[-0.68424344  0.76074266]]\n",
      "    RNN output : [[-0.68424344  0.76074266]]\n",
      "Time step 2 =>\n",
      "    Input      : [[3. 3. 3. 3. 3.]]\n",
      "    Hidden     : [[-1.3074702  1.8864892]]\n",
      "    Output     : [[-0.8649416  0.9046636]]\n",
      "    RNN output : [[-0.8649416  0.9046636]]\n"
     ]
    }
   ],
   "source": [
    "## Expanding our understanding of what the RNN layer is doing\n",
    "out = []\n",
    "for t in range(3):\n",
    "    xt = torch.reshape(x_seq[t], (1, 5))\n",
    "    print(f'Time step {t} =>')\n",
    "    print('    Input      :', xt.numpy())\n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
    "    print('    Hidden     :', ht.detach().numpy())\n",
    "    \n",
    "    if t > 0:\n",
    "        prev_h = out[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out.append(ot)\n",
    "    print('    Output     :', ot.detach().numpy())\n",
    "    print('    RNN output :', output[:, t].detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden state tensor `ht` is computed using the matrix multiplication of the input tensor `xt` and the weight matrix `w_xh` plus the bias term `b_xh`. The `detach()` method is called on `ht` to remove any gradients associated with it, and the resulting tensor is converted to a NumPy array using the `numpy()` method. This hidden state tensor represents the current state of the RNN at time step `t`.\n",
    "\n",
    "If the current time step is greater than 0, the previous hidden state tensor `prev_h` is set to the value of `out[t-1]`. Otherwise, `prev_h` is initialized to a tensor of zeros with the same shape as `ht`.\n",
    "\n",
    "The output tensor `ot` is then computed by adding `ht` to the matrix multiplication of `prev_h` and the weight matrix `w_hh` plus the bias term `b_hh`. The resulting tensor is passed through the `tanh()` activation function and the resulting tensor is stored in `ot`.\n",
    "\n",
    "The current hidden state tensor `ht` is appended to the output list out, and the values of `ot` and the corresponding element of output are printed to the console."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Activation Functions\n",
    "\n",
    "* [Hyperbolic functions](https://en.wikipedia.org/wiki/Hyperbolic_functions) - tanh, sigmoid, and ReLU\n",
    "* tanh - hyperbolic tangent\n",
    "* [torch.tanh()](https://pytorch.org/docs/stable/generated/torch.tanh.html)\n",
    "\n",
    "$$\\tanh(x) = \\frac{\\sinh{x}}{\\cosh {x}} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot a tahn activation function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of x-values\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "# Calculate the y-values of the tanh function\n",
    "y = np.tanh(x)\n",
    "\n",
    "# Plot the tanh function\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Add labels and a title to the plot\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('tanh(x)')\n",
    "plt.title('Hyperbolic Tangent Function')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: Vanishing and Exploding Gradients\n",
    "\n",
    "Backpropogration through time (BPTT) is a powerful algorithm that allows us to compute the gradients of the loss function with respect to the weights in the network. However, it is not without its problems. One of the most common problems is the vanishing and exploding gradients problem.\n",
    "\n",
    "To fully understand how our neural networks are functioning, we need to delve into gradients and backpropagation. In a nutshell, backpropagation is a method of computing the gradient of the loss function with respect to the weights in the network. This is done by computing the gradient of the loss function with respect to the output of the network, and then propagating this gradient backwards through the network. We will discuss this in more detail in the following lecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a RNN from scratch\n",
    "\n",
    "To get a working understanding of RNNs, let's implement a RNN from scratch. We will work with the IMDB dataset, which contains movie reviews and their corresponding sentiment labels. The dataset contains 50,000 reviews, 25,000 of which are labeled as positive and 25,000 as negative. The dataset is split into 25,000 training and 25,000 testing reviews. We will use the training set to train our model and the testing set to evaluate its performance.\n",
    "\n",
    "Let's begin by training a Naive Bayes on our data. We can use the performance of the Naive Bayes model as a baseline for our RNN model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br film technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mention watch oz episode hook rig...  positive\n",
       "1  wonderful little production br film technique ...  positive\n",
       "2  i think wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter mattei love time money visually stunnin...  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load our data\n",
    "df = pd.read_csv('./data/IMDB_Dataset.csv')\n",
    "\n",
    "\n",
    "## clean and preprocess the data\n",
    "## Let's preprocess our data\n",
    "import spacy\n",
    "\n",
    "NLP = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"Preprocess by tokenizing text and remove stopwords\"\"\"\n",
    "    # stopwords \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # tokenize the text with spacy\n",
    "    doc = NLP(text)\n",
    "    \n",
    "    tokens = [token.lemma_.lower() for token in doc if token.is_alpha and token.lemma_ not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "## Let's preprocess our data\n",
    "df = df[:500].copy()\n",
    "df['review'] = df['review'].apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our train and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100, 400, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the count of our train and test sets\n",
    "len(X_train), len(X_val), len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.positive_word_counts = {}\n",
    "        self.negative_word_counts = {}\n",
    "        self.positive_total_count = 0\n",
    "        self.negative_total_count = 0\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, data):\n",
    "        for text, label in data:\n",
    "            if label == 'positive':\n",
    "                self.positive_total_count += 1\n",
    "                for word in text.split():\n",
    "                    self.positive_word_counts[word] = self.positive_word_counts.get(word, 0) + 1\n",
    "                    self.vocab.add(word)\n",
    "            elif label == 'negative':\n",
    "                self.negative_total_count += 1\n",
    "                for word in text.split():\n",
    "                    self.negative_word_counts[word] = self.negative_word_counts.get(word, 0) + 1\n",
    "                    self.vocab.add(word)\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Calculate the prior probability of each class\n",
    "        positive_prior = self.positive_total_count / (self.positive_total_count + self.negative_total_count + 1e-10)\n",
    "        negative_prior = self.negative_total_count / (self.positive_total_count + self.negative_total_count + 1e-10)\n",
    "\n",
    "        # Calculate the likelihood of the text given each class\n",
    "        positive_likelihood = 0\n",
    "        negative_likelihood = 0\n",
    "        for word in text.split():\n",
    "            if word in self.vocab:\n",
    "                # Add Laplace smoothing to avoid zero probability\n",
    "                positive_likelihood += math.log((self.positive_word_counts.get(word, 0) + 1) / (self.positive_total_count + len(self.vocab) + 1))\n",
    "                negative_likelihood += math.log((self.negative_word_counts.get(word, 0) + 1) / (self.negative_total_count + len(self.vocab) + 1))\n",
    "\n",
    "        # Calculate the posterior probability of each class\n",
    "        positive_posterior = math.exp(positive_likelihood) * positive_prior\n",
    "        negative_posterior = math.exp(negative_likelihood) * negative_prior\n",
    "\n",
    "        # Return the class with the highest posterior probability\n",
    "        if positive_posterior > negative_posterior:\n",
    "            return 'positive'\n",
    "        else:\n",
    "            return 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shape our data\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.train(zip(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "## Test accuracy\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(X_val)\n",
    "\n",
    "for text, label in zip(X_val, y_val):\n",
    "    pred = nb.predict(text)\n",
    "    if pred == label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import portalocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the data\n",
    "df = pd.read_csv('./data/IMDB_Dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10000, 40000, 10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split our data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(X_val), len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "for i, review in enumerate(X_train):\n",
    "    tokens = tokenizer(review)\n",
    "    token_counts.update(tokens)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 9, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab = vocab(ordered_dict)\n",
    "\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)\n",
    "\n",
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = 'cpu'\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: 1. if x == 'pos' else 0.\n",
    "\n",
    "\n",
    "## Step 3-B: wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), \n",
    "                                      dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(X_train, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "# text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "\n",
    "# text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "# print(text_batch)\n",
    "# print(label_batch)\n",
    "# print(length_batch)\n",
    "# print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(X_train, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(X_val, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1991,  0.8657,  0.2444],\n",
      "         [-0.6629,  0.8073,  1.1017],\n",
      "         [ 0.0612, -0.6177,  0.7312],\n",
      "         [ 1.1718, -0.9274,  0.5451]],\n",
      "\n",
      "        [[ 0.0612, -0.6177,  0.7312],\n",
      "         [-0.1759, -2.2456, -1.4465],\n",
      "         [-0.6629,  0.8073,  1.1017],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=10, \n",
    "                         embedding_dim=3, \n",
    "                         padding_idx=0)\n",
    " \n",
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2122],\n",
       "        [-0.2387],\n",
       "        [ 0.2438],\n",
       "        [-0.1354],\n",
       "        [-0.4309]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## An example of building a RNN model\n",
    "## with simple RNN layer\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=2, \n",
    "                          batch_first=True)\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(64, 32) \n",
    "\n",
    "print(model) \n",
    " \n",
    "model(torch.randn(5, 3, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4894",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4894",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 9\u001b[0m     acc_train, loss_train \u001b[39m=\u001b[39m train(train_dl)\n\u001b[1;32m     10\u001b[0m     acc_valid, loss_valid \u001b[39m=\u001b[39m evaluate(valid_dl)\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc_train\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m val_accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc_valid\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m total_acc, total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m text_batch, label_batch, lengths \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m     pred \u001b[39m=\u001b[39m model(text_batch, lengths)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/core/series.py:1012\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1011\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1015\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1017\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1120\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1121\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 4894"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10 \n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources (Continued Reading)\n",
    "\n",
    "* [Andrej Karpathy's blog post on word embeddings](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* [A Visual Introduction to Word Embeddings](https://jalammar.github.io/illustrated-word2vec/)\n",
    "* [A Visual Introduction to Machine Learning](https://jalammar.github.io/visual-interactive-guide-basics-machine-learning-algorithms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d99a3f87c484a74ba405ca572f7f1b4059e93a8c4d7f8027bf5ae12e7919d9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
