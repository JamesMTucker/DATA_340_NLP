{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 23: 2023-04-20 Exploring Applied NLP Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Overview\n",
    "\n",
    "* Named Entity Recognition (NER) using SpaCy and Transformers\n",
    "* Text summarization using Transformers\n",
    "* Text generation using Transformers\n",
    "* Analyzing `Fake news` using Transformers and ChatGPT\n",
    "* Semantic role labeling using Transformers and ChatGPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER) using SpaCy and Transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition (NER) is the task of identifying named entities in text and classifying them into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 13:45:39.662378: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-20 13:45:39.682355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 13:45:40.039081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-20 13:45:40.486133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 13:45:40.486665: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/james/miniconda3/envs/tf_2_11/lib/python3.10/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/james/miniconda3/envs/tf_2_11/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Apple is type ORG - index_location: 0:5\n",
      "Entity: U.K. is type GPE - index_location: 27:31\n",
      "Entity: $1 billion is type MONEY - index_location: 44:54\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'Entity: {ent.text} is type {ent.label_} - index_location: {ent.start_char}:{ent.end_char}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: 1:1 is type DATE - index_location: 46:49\n",
      "Entity: Eight-seven percent is type PERCENT - index_location: 98:117\n",
      "Entity: 60 is type CARDINAL - index_location: 135:137\n",
      "Entity: PD is type NORP - index_location: 183:185\n",
      "Entity: dyskinesia is type GPE - index_location: 328:338\n",
      "Entity: 56% is type PERCENT - index_location: 371:374\n",
      "Entity: 14 is type CARDINAL - index_location: 396:398\n",
      "Entity: daily is type DATE - index_location: 464:469\n",
      "Entity: 31 is type CARDINAL - index_location: 512:514\n",
      "Entity: 22 is type CARDINAL - index_location: 530:532\n",
      "Entity: 4 is type CARDINAL - index_location: 667:668\n"
     ]
    }
   ],
   "source": [
    "### more complex data\n",
    "\n",
    "# https://pubmed.ncbi.nlm.nih.gov/37071411/\n",
    "text = \"\"\"\n",
    "Most patients were initially certified for a 1:1 (∆9-tetrahydrocannabinol:cannabidiol) tincture.\n",
    "Eight-seven percent of patients (n = 60) were noted to exhibit an improvement in any PD symptom after starting MC.\n",
    "Symptoms with the highest incidence of improvement included cramping/dystonia, pain, spasticity, lack of appetite, dyskinesia, and tremor.\n",
    "After starting MC, 56% of opioid users (n = 14) were able to decrease or discontinue opioid use with an average daily morphine milligram equivalent change from 31 at baseline to 22 at the last follow-up visit.\n",
    "The MC was well-tolerated with no severe AEs reported and low rate of MC discontinuation due to AEs (n = 4).\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'Entity: {ent.text} is type {ent.label_} - index_location: {ent.start_char}:{ent.end_char}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: patients is type ENTITY - index_location: 6:14\n",
      "Entity: ∆9-tetrahydrocannabinol:cannabidiol) tincture is type ENTITY - index_location: 51:96\n",
      "Entity: patients is type ENTITY - index_location: 121:129\n",
      "Entity: improvement is type ENTITY - index_location: 164:175\n",
      "Entity: PD is type ENTITY - index_location: 183:185\n",
      "Entity: symptom is type ENTITY - index_location: 186:193\n",
      "Entity: MC is type ENTITY - index_location: 209:211\n",
      "Entity: Symptoms is type ENTITY - index_location: 213:221\n",
      "Entity: incidence is type ENTITY - index_location: 239:248\n",
      "Entity: improvement is type ENTITY - index_location: 252:263\n",
      "Entity: cramping/dystonia is type ENTITY - index_location: 273:290\n",
      "Entity: pain is type ENTITY - index_location: 292:296\n",
      "Entity: spasticity is type ENTITY - index_location: 298:308\n",
      "Entity: lack of appetite is type ENTITY - index_location: 310:326\n",
      "Entity: dyskinesia is type ENTITY - index_location: 328:338\n",
      "Entity: tremor is type ENTITY - index_location: 344:350\n",
      "Entity: MC is type ENTITY - index_location: 367:369\n",
      "Entity: opioid is type ENTITY - index_location: 378:384\n",
      "Entity: users is type ENTITY - index_location: 385:390\n",
      "Entity: decrease is type ENTITY - index_location: 413:421\n",
      "Entity: discontinue is type ENTITY - index_location: 425:436\n",
      "Entity: opioid is type ENTITY - index_location: 437:443\n",
      "Entity: daily is type ENTITY - index_location: 464:469\n",
      "Entity: morphine is type ENTITY - index_location: 470:478\n",
      "Entity: milligram is type ENTITY - index_location: 479:488\n",
      "Entity: baseline is type ENTITY - index_location: 518:526\n",
      "Entity: follow-up is type ENTITY - index_location: 545:554\n",
      "Entity: visit is type ENTITY - index_location: 555:560\n",
      "Entity: MC is type ENTITY - index_location: 566:568\n",
      "Entity: AEs is type ENTITY - index_location: 603:606\n",
      "Entity: low rate is type ENTITY - index_location: 620:628\n",
      "Entity: MC is type ENTITY - index_location: 632:634\n",
      "Entity: discontinuation is type ENTITY - index_location: 635:650\n",
      "Entity: AEs is type ENTITY - index_location: 658:661\n"
     ]
    }
   ],
   "source": [
    "## Using SciSpacy\n",
    "\n",
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_scibert\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'Entity: {ent.text} is type {ent.label_} - index_location: {ent.start_char}:{ent.end_char}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 829/829 [00:00<00:00, 1.29MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 433M/433M [00:12<00:00, 36.1MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 59.0/59.0 [00:00<00:00, 180kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 2.96MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 4.85kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 202kB/s]\n",
      "/home/james/miniconda3/envs/tf_2_11/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:159: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.9794678,\n",
       "  'word': 'PD',\n",
       "  'start': 183,\n",
       "  'end': 185},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.75518626,\n",
       "  'word': 'MC',\n",
       "  'start': 209,\n",
       "  'end': 211},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.74572164,\n",
       "  'word': 'MC',\n",
       "  'start': 367,\n",
       "  'end': 369},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.67157006,\n",
       "  'word': 'MC',\n",
       "  'start': 566,\n",
       "  'end': 568},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.5219626,\n",
       "  'word': 'A',\n",
       "  'start': 603,\n",
       "  'end': 604},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.65227294,\n",
       "  'word': 'MC',\n",
       "  'start': 632,\n",
       "  'end': 634}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline('ner', model='dslim/bert-base-NER', tokenizer='dslim/bert-base-NER', grouped_entities=True)\n",
    "ner(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Lab_value',\n",
       "  'score': 0.4000886,\n",
       "  'word': '1',\n",
       "  'start': 46,\n",
       "  'end': 47},\n",
       " {'entity_group': 'Lab_value',\n",
       "  'score': 0.9972366,\n",
       "  'word': 'eight - seven percent',\n",
       "  'start': 98,\n",
       "  'end': 117},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.99834895,\n",
       "  'word': 'pd',\n",
       "  'start': 183,\n",
       "  'end': 185},\n",
       " {'entity_group': 'Sign_symptom',\n",
       "  'score': 0.9996455,\n",
       "  'word': 'cr',\n",
       "  'start': 273,\n",
       "  'end': 275},\n",
       " {'entity_group': 'Sign_symptom',\n",
       "  'score': 0.9379781,\n",
       "  'word': '##amp',\n",
       "  'start': 275,\n",
       "  'end': 278},\n",
       " {'entity_group': 'Sign_symptom',\n",
       "  'score': 0.74788606,\n",
       "  'word': 'd',\n",
       "  'start': 282,\n",
       "  'end': 283},\n",
       " {'entity_group': 'Sign_symptom',\n",
       "  'score': 0.98544145,\n",
       "  'word': 'spa',\n",
       "  'start': 298,\n",
       "  'end': 301},\n",
       " {'entity_group': 'Sign_symptom',\n",
       "  'score': 0.9243543,\n",
       "  'word': 'dyskines',\n",
       "  'start': 328,\n",
       "  'end': 336},\n",
       " {'entity_group': 'Lab_value',\n",
       "  'score': 0.74904835,\n",
       "  'word': '56 %',\n",
       "  'start': 371,\n",
       "  'end': 374},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.9088081,\n",
       "  'word': 'op',\n",
       "  'start': 378,\n",
       "  'end': 380},\n",
       " {'entity_group': 'Medication',\n",
       "  'score': 0.8767638,\n",
       "  'word': 'op',\n",
       "  'start': 437,\n",
       "  'end': 439},\n",
       " {'entity_group': 'Medication',\n",
       "  'score': 0.7715019,\n",
       "  'word': '##phine',\n",
       "  'start': 473,\n",
       "  'end': 478},\n",
       " {'entity_group': 'Dosage',\n",
       "  'score': 0.49743292,\n",
       "  'word': '##ram',\n",
       "  'start': 485,\n",
       "  'end': 488},\n",
       " {'entity_group': 'Lab_value',\n",
       "  'score': 0.9992072,\n",
       "  'word': '31',\n",
       "  'start': 512,\n",
       "  'end': 514},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.99966466,\n",
       "  'word': 'mc',\n",
       "  'start': 566,\n",
       "  'end': 568},\n",
       " {'entity_group': 'Severity',\n",
       "  'score': 0.99415165,\n",
       "  'word': 'severe',\n",
       "  'start': 596,\n",
       "  'end': 602},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.9994223,\n",
       "  'word': 'ae',\n",
       "  'start': 603,\n",
       "  'end': 605},\n",
       " {'entity_group': 'Lab_value',\n",
       "  'score': 0.98854595,\n",
       "  'word': 'low',\n",
       "  'start': 620,\n",
       "  'end': 623},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.9996766,\n",
       "  'word': 'mc',\n",
       "  'start': 632,\n",
       "  'end': 634},\n",
       " {'entity_group': 'Disease_disorder',\n",
       "  'score': 0.9996525,\n",
       "  'word': 'ae',\n",
       "  'start': 658,\n",
       "  'end': 660}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/d4data/biomedical-ner-all\n",
    "ner = pipeline('ner', model='d4data/biomedical-ner-all', tokenizer='d4data/biomedical-ner-all', grouped_entities=True)\n",
    "ner(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own pipeline\n",
    "\n",
    "* Extract semantic triples from the text then perform NER on the extracted triples\n",
    "* Use Stanford CoreNLP to extract semantic triples from the text then perform NER on the extracted triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:19:19 WARNING: Directory /home/james/stanza_corenlp already exists. Please install CoreNLP to a new directory.\n",
      "2023-04-20 14:19:19 INFO: Writing properties to tmp file: corenlp_server-8f4d98135c864d8d.props\n",
      "2023-04-20 14:19:19 INFO: Starting server with command: java -Xmx16G -cp /home/james/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9020 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8f4d98135c864d8d.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref,openie -preload -outputFormat serialized\n",
      "[main] INFO CoreNLP - --- StanfordCoreNLPServer#main() called ---\n",
      "[main] INFO CoreNLP - Server default properties:\n",
      "\t\t\t(Note: unspecified annotator properties are English defaults)\n",
      "\t\t\tannotators = tokenize,ssplit,pos,lemma,ner,parse,depparse,coref,openie\n",
      "\t\t\tinputFormat = text\n",
      "\t\t\toutputFormat = serialized\n",
      "\t\t\tprettyPrint = false\n",
      "\t\t\tthreads = 5\n",
      "[main] INFO CoreNLP - Threads: 5\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [0.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.2 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.2 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580705 unique entries out of 581864 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4867 unique entries out of 4867 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585572 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.NERCombinerAnnotator - numeric classifiers: true; SUTime: true [no docDate]; fine grained: true\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 0.5 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 0.423 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [0.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.012 seconds]\n",
      "[main] ERROR CoreNLP - Could not pre-load annotators in server; encountered exception:\n",
      "[main] ERROR CoreNLP - java.lang.IllegalArgumentException: annotator \"openie\" requires annotation \"PolarityAnnotation\". The usual requirements for this annotator are: tokenize,pos,lemma,depparse,natlog\n",
      "  edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:292)\n",
      "  edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:194)\n",
      "  edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:190)\n",
      "  edu.stanford.nlp.pipeline.StanfordCoreNLPServer.launchServer(StanfordCoreNLPServer.java:1622)\n",
      "  edu.stanford.nlp.pipeline.StanfordCoreNLPServer.main(StanfordCoreNLPServer.java:1644)\n",
      "[main] INFO CoreNLP - Starting server...\n",
      "[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0.0.0.0:9020\n",
      "[pool-1-thread-3] INFO CoreNLP - [/127.0.0.1:53872] API call w/annotators tokenize,pos,lemma,ner,parse,depparse,natlog,coref,openie\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most patients were initially certified for a 1:1 (∆9-tetrahydrocannabinol:cannabidiol) tincture. Eight-seven percent of patients (n = 60) were noted to exhibit an improvement in any PD symptom after starting MC. Symptoms with the highest incidence of improvement included cramping/dystonia, pain, spasticity, lack of appetite, dyskinesia, and tremor. After starting MC, 56% of opioid users (n = 14) were able to decrease or discontinue opioid use with an average daily morphine milligram equivalent change from 31 at baseline to 22 at the last follow-up visit. The MC was well-tolerated with no severe AEs reported and low rate of MC discontinuation due to AEs (n = 4). \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['patients', 'were', 'initially certified'],\n",
       " ['patients', 'were certified for', '1:1'],\n",
       " ['Most patients', 'were certified for', '1:1'],\n",
       " ['Most patients', 'were initially certified for', '1:1'],\n",
       " ['patients', 'were initially certified for', '1:1'],\n",
       " ['patients', 'were', 'certified'],\n",
       " ['Most patients', 'were', 'certified'],\n",
       " ['Most patients', 'were', 'initially certified'],\n",
       " ['improvement', 'is in', 'PD symptom'],\n",
       " ['Eight seven percent', 'were', 'noted'],\n",
       " ['Eight seven percent', 'exhibit', 'improvement in PD symptom'],\n",
       " ['dystonia', 'lack of', 'appetite'],\n",
       " ['Symptoms', 'is with', 'highest incidence of improvement'],\n",
       " ['Symptoms', 'included', 'cramping dystonia'],\n",
       " ['Symptoms', 'included', 'lack'],\n",
       " ['Symptoms', 'included', 'lack of appetite']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stanza\n",
    "import spacy\n",
    "from stanza.server import CoreNLPClient\n",
    "stanza.install_corenlp()\n",
    "\n",
    "## extract triples from the text\n",
    "triples = []\n",
    "\n",
    "# define the properties\n",
    "config = {\n",
    "    \"annotators\": \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref,openie\",\n",
    "    \"openie.max_entailments_per_clause\": \"100\",\n",
    "    \"openie.threads\": \"4\",\n",
    "    \"memory\": \"16G\",\n",
    "    \"endpoint\": \"http://localhost:9020\",\n",
    "}\n",
    "\n",
    "client = CoreNLPClient(annotators=config['annotators'], memory=config['memory'], endpoint=config['endpoint'])\n",
    "\n",
    "document = client.annotate(text)\n",
    "for i, sentence in enumerate(document.sentence):\n",
    "    for triple in sentence.openieTriple:\n",
    "        triples.append([triple.subject, triple.relation, triple.object])\n",
    "        \n",
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Most patients were initially certified for a 1:1 (∆9-tetrahydrocannabinol:cannabidiol) tincture.\n",
       "Eight-seven percent of patients (n = 60) were noted to exhibit an improvement in any PD symptom after starting MC.\n",
       "Symptoms with the highest incidence of improvement included cramping/dystonia, pain, spasticity, lack of appetite, dyskinesia, and tremor.\n",
       "After starting MC, 56% of opioid users (n = 14) were able to decrease or discontinue opioid use with an average daily morphine milligram equivalent change from 31 at baseline to 22 at the last follow-up visit.\n",
       "The MC was well-tolerated with no severe AEs reported and low rate of MC discontinuation due to AEs (n = 4).\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: patients is type ENTITY - index_location: 0:8\n",
      "Entity: patients is type ENTITY - index_location: 0:8\n",
      "Entity: patients is type ENTITY - index_location: 5:13\n",
      "Entity: patients is type ENTITY - index_location: 5:13\n",
      "Entity: patients is type ENTITY - index_location: 0:8\n",
      "Entity: patients is type ENTITY - index_location: 0:8\n",
      "Entity: patients is type ENTITY - index_location: 5:13\n",
      "Entity: patients is type ENTITY - index_location: 5:13\n",
      "Entity: improvement is type ENTITY - index_location: 0:11\n",
      "Entity: PD is type ENTITY - index_location: 18:20\n",
      "Entity: symptom is type ENTITY - index_location: 21:28\n",
      "Entity: improvement is type ENTITY - index_location: 28:39\n",
      "Entity: PD is type ENTITY - index_location: 43:45\n",
      "Entity: symptom is type ENTITY - index_location: 46:53\n",
      "Entity: dystonia is type ENTITY - index_location: 0:8\n",
      "Entity: lack of appetite is type ENTITY - index_location: 9:25\n",
      "Entity: Symptoms is type ENTITY - index_location: 0:8\n",
      "Entity: incidence is type ENTITY - index_location: 25:34\n",
      "Entity: improvement is type ENTITY - index_location: 38:49\n",
      "Entity: Symptoms is type ENTITY - index_location: 0:8\n",
      "Entity: cramping is type ENTITY - index_location: 18:26\n",
      "Entity: dystonia is type ENTITY - index_location: 27:35\n",
      "Entity: Symptoms is type ENTITY - index_location: 0:8\n",
      "Entity: lack is type ENTITY - index_location: 18:22\n",
      "Entity: Symptoms is type ENTITY - index_location: 0:8\n",
      "Entity: lack of appetite is type ENTITY - index_location: 18:34\n"
     ]
    }
   ],
   "source": [
    "## Analyze the triples for NER\n",
    "\n",
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_scibert\")\n",
    "\n",
    "for i, triple in enumerate(triples):\n",
    "    doc = \" \".join(triple)\n",
    "    doc = nlp(doc)\n",
    "    for ent in doc.ents:\n",
    "        print(f'Entity: {ent.text} is type {ent.label_} - index_location: {ent.start_char}:{ent.end_char}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization using Transformers\n",
    "\n",
    "There are two types of text summarization:\n",
    "\n",
    "* Extractive summarization: Extracting a subset of the original text to form the summary\n",
    "* Abstractive summarization: Generating new text to form the summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive summarization\n",
    "\n",
    "There are several extractive summarization techniques:\n",
    "\n",
    "* LexRank - LexRank is a graph-based algorithm that uses the PageRank algorithm to rank sentences based on their similarity to other sentences in the text.\n",
    "* SentRank - SentRank is a graph-based algorithm that uses the PageRank algorithm to rank sentences based on their similarity to other sentences in the text.\n",
    "* Luhn - Uses TF-IDF to rank sentences based on their similarity to other sentences in the text.\n",
    "* SumBasic - Utilize the frequency of words in the text to rank sentences. (abstract-like)\n",
    "* KL-Sum - Kullback-Leibler divergence is used to rank sentences based on their similarity to other sentences in the text.\n",
    "* LSA - Latent semantic analysis or indexing uses singular value decomposition to compute matrices for analyzing relationships between sets of observations.\n",
    "* K-Means - K-means clustering is a method of vector quantization, originally from signal processing, that is popular for cluster analysis in data mining."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 693/693 [00:00<00:00, 1.24MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.12G/1.12G [00:34<00:00, 32.0MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 520kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:00<00:00, 32.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 154kB/s]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "from transformers import BloomTokenizerFast\n",
    "from transformers import BloomForCausalLM\n",
    "\n",
    "MODEL = BloomForCausalLM.from_pretrained('bigscience/bloom-560m')\n",
    "TOKENIZER = BloomTokenizerFast.from_pretrained('bigscience/bloom-560m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarization of our text using the Bloom model\n",
    "\n",
    "def summarize_text(text: str, tokenizer=TOKENIZER, min_output=40, max_output=100, max_length=80, model=MODEL):\n",
    "    \"\"\"Take a string of text and generate a summary\"\"\"\n",
    "    tokens_input = tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=max_length, truncation=True)\n",
    "    ids = model.generate(tokens_input, min_length=min_output, max_length=max_output)\n",
    "    summary = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "summarize: \n",
       "Most patients were initially certified for a 1:1 (∆9-tetrahydrocannabinol:cannabidiol) tincture.\n",
       "Eight-seven percent of patients (n = 60) were noted to exhibit an improvement in any PD symptom after starting MC.\n",
       "Symptoms with the highest incidence of improvement included cramping/dystonia, pain, spasticity, and fatigue. The most common side effects were nausea, vomiting, and diarrhea."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = summarize_text(text)\n",
    "display(HTML(summary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News\n",
    "\n",
    "What is fake news?\n",
    "\n",
    "* Fake news is a type of yellow journalism or propaganda that consists of deliberate misinformation or hoaxes spread via traditional print and broadcast news media or online social media.\n",
    "* Fake news can be published to intentionally or circumstantially damage the reputation of a person or entity, or make money through advertising revenue.\n",
    "* But ... fake news is not always false. The label can be used to discredit news that is critical of a person or organization, or to draw attention away from critical analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake News Detection processing\n",
    "\n",
    "* Is it a news article?\n",
    "* Is there consensus on the truthfulness of the article?\n",
    "* If yes, return the consensus\n",
    "* If no, continue\n",
    "  * What is challenged in the article?\n",
    "    * Sentiment analysis - can shed light on the overall tone of the article (positive, negative, neutral) - heatmap of the article by paragraph or section\n",
    "    * Named entity recognition - can we identify the entities in the article (people, places, organizations, etc.)\n",
    "    * Can we perform semantic role labeling on the article?\n",
    "    * Are there references to other sources?\n",
    "\n",
    "\n",
    "\n",
    "adapted from Rothman, D. _Transformers for Natural Language Processing_. O'Reilly Media, Inc., 2020"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example](https://github.com/Denis2054/Transformers-for-NLP-2nd-Edition/blob/main/Chapter13/Fake_News_Analysis_with_ChatGPT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
