{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: 2021-07-03 Naive Bayes Classifier II"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Lecture Outline\n",
    "\n",
    "- Assignments and Grades\n",
    "- Example of NLP research [ChatGPT](https://arxiv.org/pdf/2302.13795.pdf)\n",
    "- Naive Bayes Classification\n",
    "  - Continuous\n",
    "  - Multinomial\n",
    "- Naive Bayes Classifier\n",
    "  - Example\n",
    "  - Implementation\n",
    "  - Evaluation\n",
    "  - Comparison with Logistic Regression\n",
    "\n",
    "Keyterms: #model, #heuristic, #Bernoulli, #Prior, #Likelihood, #Evidence, #Posterior, #Vocabulary, #Laplace_Smoothing, #Tokenization, #Features, #TF-IDF, #Vectorization, #Stopwords, #Stemming, #Lemmatization, #Naive_Bayes_Classifier, #Multinomial, #Continuous, #Evaluation, #Accuracy, #Precision, #Recall, #F1_Score, #Confusion_Matrix, #ROC_Curve, #AUC, #Logistic_Regression, #Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary of the Naive Bayes Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Background Assumptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem is a fundamental result in statistics and machine learning. It is used to compute the posterior probability of an event given some evidence. To understand Bayes theorem, let's assume we have two events $A$ and $B$. We let $A$ stand for a movie review being positive and $B$ stand for the review being negative. We want to compute the probability that a review is positive given that the review contains the word \"excellent\". Thus, we have two classes where the membership of $x$ is deteremined by the words contained in the review or `document`: $c_i = \\{d \\space | \\space d \\space is \\space positive\\}$ and $c_j = \\{d \\space | \\space d \\space is \\space negative\\}$.\n",
    "\n",
    "So we can ask the question: \"What is the probability that a review is positive given that the review contains the word \"excellent\"?\n",
    "\n",
    "$$P('excellent'|positive)$$\n",
    "\n",
    "If we assumed the presence of one word is dependent on the presence of any other word in our vocabulary, we would therefore have to compute the chain probability of an array of words with every word in our vocabulary:\n",
    "\n",
    "$$P(d|v) = P(w_1, w_2, \\ldots, w_n|v) = P(w_1|v)P(w_2|v)\\ldots P(w_n|v)$$\n",
    "\n",
    "This of course is computationally infeasible. So we make the assumption that the presence of one word is independent of the presence of any other word in our vocabulary. This is called the Naive Bayes assumption. This assumption is naive because it is not true in general. However, it is a good approximation in many cases. We can write the probability of a document $d$ given a class $c$ as:\n",
    "\n",
    "$$P(d|c) = P(w_1|c)P(w_2|c)\\ldots P(w_n|c)$$\n",
    "\n",
    "\n",
    "We have simplified the problem, yet we have introduced a `bias`. The `bias` betrays our understanding of linguistic experience where it is natural to assume the presence of one word is conditionally dependent on the presence of other words: e.g, `Richmond, Virginia`.\n",
    "\n",
    "We can now compute the probability that a review is positive given that the review contains the word \"excellent\":\n",
    "\n",
    "$$\\frac{P(positive) \\times P('excellent'|positive)}{P(positive) \\times P('excellent'|positive) + P(negative) \\times P('excellent'|negative)}$$\n",
    "\n",
    "So we can understand the proir, likelihood, evidence, and posterior as follows:\n",
    "\n",
    "`Priors` = $P(positive)$ and $P(negative)$ <br>\n",
    "\n",
    "`likelihoods` = $P('excellent'|positive)$ and $P('excellent'|negative)$\n",
    "\n",
    "`evidence` = $P(positive) \\times P('excellent'|positive) + P(negative) \\times P('excellent'|negative)$\n",
    "\n",
    "`posterior` = $\\frac{P(positive) \\times P('excellent'|positive)}{P(positive) \\times P('excellent'|positive) + P(negative) \\times P('excellent'|negative)}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data Preprocessing steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now featurize our data by the following steps:\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords removed (low information words)\n",
    "- Strip punctuation (low semantic value)\n",
    "- Stemming or Lemmatization\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Classifier for Sentiment Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Twitter Sentiment Analysis\n",
    "\n",
    "In this example, we will use the [Twitter US Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) dataset from Kaggle. The dataset contains 14,640 tweets from 6 US airlines. The tweets are labeled as positive, negative, or neutral. The goal is to predict the sentiment of a tweet given the text of the tweet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import our libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Defining our negative and positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "## check the number of positive and negative tweets\n",
    "len(pos_tweets), len(neg_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## examine some random samples\n",
    "print('Positive tweet:', pos_tweets[random.randint(0,5000)])\n",
    "print('Negative tweet:', neg_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Input: tweet a string containing a tweet\n",
    "    Return:\n",
    "    tweets_clean: a list of words containing the processed tweet\n",
    "    \"\"\"\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    # remove retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # Instantiate stemmer class\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Create stopwords list\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # Tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    \n",
    "    # Tokenize the tweets\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and word not in string.punctuation):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "    \n",
    "    return tweets_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Let's create our train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pos_tweets + neg_tweets,\n",
    "                                                    np.append(np.ones(len(pos_tweets)),\n",
    "                                                    np.zeros(len(neg_tweets))),\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counts of positive and negative tweets\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine some random samples\n",
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "print('Tweet:', X_train[idx])\n",
    "print('Tweet label:', y_train[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Let's define our frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a dictionary of words and their frequencies\n",
    "def count_tweets(result, tweets, ys):\n",
    "    \"\"\"Input:\n",
    "    result: a dictionary that will contain the frequency of each pair (word, label)\n",
    "    tweets: a list of tweets\n",
    "    ys: an m x 1 array with the sentiment label of each tweet (either 0 or 1)\n",
    "    \"\"\"\n",
    "    # iterate through each tweet and its label\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        # process the tweet to get the words in the form of a list\n",
    "        for word in process_tweet(tweet):\n",
    "            # increment the word count for the pair (word, label)\n",
    "            pair = (word, y)\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = count_tweets({}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs[('happi', 1.0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Let's define our Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a function to extract the features from the tweets\n",
    "\n",
    "def train_naive_bayes(freqs, X, y):\n",
    "    \"\"\"Train a Naive Bayes classifier on twitter data.\n",
    "\n",
    "    Args:\n",
    "        freqs (dict): dictionary of (word, label): frequency pairs\n",
    "        X_train (list): list of tweets\n",
    "        y_train (list): list of tweets\n",
    "        \n",
    "    returns:\n",
    "    logprior (float): log prior\n",
    "    loglikelihood (dict): dictionary of (word, label): log likelihood pairs\n",
    "    \"\"\"\n",
    "    ## Compare the code here with Jurafsky and Martin's pseudocode\n",
    "    \n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "    \n",
    "    vocab = set([pair[0] for pair in freqs.keys()]) # words in the vocabulary\n",
    "    V = len(vocab) # number of unique words in the vocabulary\n",
    "    \n",
    "    # Calculate N_pos and N_neg tweets (number of positive and negative tweets)\n",
    "    N_pos, N_neg = 0, 0 # number of positive and negative tweets\n",
    "    \n",
    "    # Calculate the number of positive and negative tweets\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair] # positive tweets\n",
    "        else:\n",
    "            N_neg += freqs[pair] # negative tweets\n",
    "    \n",
    "    # Documents = total number of tweets\n",
    "    D = len(X)\n",
    "    \n",
    "    # Calculate # of positive and negative documents\n",
    "    D_pos = np.sum(y)\n",
    "    D_neg = D - D_pos\n",
    "    \n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "    \n",
    "    for word in vocab:\n",
    "        \n",
    "        freq_pos = freqs.get((word, 1.0), 0)\n",
    "        freq_neg = freqs.get((word, 0.0), 0)\n",
    "        \n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "        \n",
    "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
    "    \n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. Let's train our Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's test our function\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9. Let's test our Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(tweet, logprior, loglikelihood):\n",
    "    \"\"\"Input:\n",
    "    tweet: a string\n",
    "    logprior: a number\n",
    "    loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "    p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
    "    \"\"\"\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    p = 0\n",
    "    p += logprior\n",
    "    \n",
    "    for word in word_l:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    \n",
    "    return p\n",
    "\n",
    "def test_naive_bayes(X_test, y_test, logprior, loglikelihood):\n",
    "    \"\"\"Input:\n",
    "    X_test: a list of tweets\n",
    "    y_test: (m, 1) array with the sentiment label of each tweet (either 0 or 1)\n",
    "    logprior: a number\n",
    "    loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "    accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let's score the accuracy of our model\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Our predictions will be stored in y_hat\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in X_test:\n",
    "        if predict_naive_bayes(tweet, logprior, loglikelihood) > 0:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "    \n",
    "    # error is the average of the absolute values of the differences between y_hat and y_test\n",
    "    error = np.mean(np.abs(y_hat - y_test))\n",
    "    \n",
    "    accuracy = 1 - error\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes accuracy = %f\" % test_naive_bayes(X_test, y_test, logprior, loglikelihood))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes Classifier for Binary Classification: Movie Review Sentiment Analysis\n",
    "\n",
    "\n",
    "In the above, we precomputed the frequency of each word in our vocabulary. We can, however, implement a Naive Bayes classifier in a different manner. In this example, we will create some classes that will allow us to train a Naive Bayes classifier on the fly. We will use the [IMDB Movie Review Dataset](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) from Kaggle. The dataset contains 50,000 movie reviews from IMDB. The reviews are labeled as positive or negative. The goal is to predict the sentiment of a movie review given the text of the review."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## html display\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Read data and create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a dataframe to store the results\n",
    "\n",
    "## if you are working in Colab replace the path with the url:\n",
    "# imdb_dataset = 'https://github.com/JamesMTucker/DATA_340_NLP/blob/master/Notebooks/data/IMDB_Dataset.csv'\n",
    "\n",
    "df = pd.read_csv('data/IMDB_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create our train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the count of our train and test sets\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly select a sample from the training set\n",
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "# display the sample in HTML format\n",
    "print(display(HTML(f\"<p>Tweet: {X_train.iloc[idx]}</p>\")))\n",
    "print('label:', y_train.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.positive_word_counts = {}\n",
    "        self.negative_word_counts = {}\n",
    "        self.positive_total_count = 0\n",
    "        self.negative_total_count = 0\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, data):\n",
    "        for text, label in data:\n",
    "            if label == 'positive':\n",
    "                self.positive_total_count += 1\n",
    "                for word in text.split():\n",
    "                    self.positive_word_counts[word] = self.positive_word_counts.get(word, 0) + 1\n",
    "                    self.vocab.add(word)\n",
    "            elif label == 'negative':\n",
    "                self.negative_total_count += 1\n",
    "                for word in text.split():\n",
    "                    self.negative_word_counts[word] = self.negative_word_counts.get(word, 0) + 1\n",
    "                    self.vocab.add(word)\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Calculate the prior probability of each class\n",
    "        positive_prior = self.positive_total_count / (self.positive_total_count + self.negative_total_count + 1e-10)\n",
    "        negative_prior = self.negative_total_count / (self.positive_total_count + self.negative_total_count + 1e-10)\n",
    "\n",
    "        # Calculate the likelihood of the text given each class\n",
    "        positive_likelihood = 0\n",
    "        negative_likelihood = 0\n",
    "        for word in text.split():\n",
    "            if word in self.vocab:\n",
    "                # Add Laplace smoothing to avoid zero probability\n",
    "                positive_likelihood += math.log((self.positive_word_counts.get(word, 0) + 1) / (self.positive_total_count + len(self.vocab) + 1))\n",
    "                negative_likelihood += math.log((self.negative_word_counts.get(word, 0) + 1) / (self.negative_total_count + len(self.vocab) + 1))\n",
    "\n",
    "        # Calculate the posterior probability of each class\n",
    "        positive_posterior = math.exp(positive_likelihood) * positive_prior\n",
    "        negative_posterior = math.exp(negative_likelihood) * negative_prior\n",
    "\n",
    "        # Return the class with the highest posterior probability\n",
    "        if positive_posterior > negative_posterior:\n",
    "            return 'positive'\n",
    "        else:\n",
    "            return 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shape our data\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.train(zip(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test random sample\n",
    "random_idx = random.randint(0, len(X_test))\n",
    "result = nb.predict(X_test.iloc[random_idx])\n",
    "print(display(HTML(f\"<p>Tweet: {X_test.iloc[random_idx]}</p> <p>{y_test.iloc[random_idx]}</p>\")))\n",
    "print('prediction:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test accuracy\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(X_test)\n",
    "\n",
    "for text, label in zip(X_test, y_test):\n",
    "    pred = nb.predict(text)\n",
    "    if pred == label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Can we improve our model with vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a dataframe to store the results\n",
    "\n",
    "## if you are working in Colab replace the path with the url:\n",
    "# imdb_dataset = 'https://github.com/JamesMTucker/DATA_340_NLP/blob/master/Notebooks/data/IMDB_Dataset.csv'\n",
    "\n",
    "df = pd.read_csv('data/IMDB_Dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's convert the sentiment to labels\n",
    "sentiment = {'positive': 1, 'negative': 0}\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map(sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define our X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using the CountVectorizer class\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "validation_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier using the MultinomialNB class\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_vectors, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions = classifier.predict(validation_vectors)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')  # Output: Accuracy: 0.80"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Naive Bayes Classifier for Multiclass Classification: Airline review sentiment analysis\n",
    "\n",
    "In this example, we will use the [Twitter US Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) dataset from Kaggle. The dataset contains 14,640 tweets from 6 US airlines. The tweets are labeled as positive, negative, or neutral. The goal is to predict the sentiment of a tweet given the text of the tweet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Read our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are working in Colab replace the path with the url:\n",
    "# airline_tweets = 'https://raw.githubusercontent.com/JamesMTucker/DATA_340_NLP/master/Notebooks/data/Tweets.csv'\n",
    "\n",
    "df = pd.read_csv('data/Tweets.csv')\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Keep the tweet and label the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "\n",
    "df['airline_sentiment'] = df['airline_sentiment'].map(sentiment)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Create our train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['airline_sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Create our text vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on our corpus\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Train and evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "nb.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test_vectors)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Let's see where our model is making mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## visualize the confusion matrix\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "## plot the confusion matrix\n",
    "sns.heatmap(cfm, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.7. Let's see some of the mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output some of the misclassified tweets\n",
    "misclassified = np.where(y_pred != y_test)[0]\n",
    "print('Misclassified tweets:', len(misclassified))\n",
    "\n",
    "## create a dataframe to store the misclassified tweets\n",
    "misclassified_df = pd.DataFrame({'text': X_test.iloc[misclassified], 'actual': y_test.iloc[misclassified], 'predicted': y_pred[misclassified]})\n",
    "misclassified_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes Optimizations with TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a TF-IDF vectorizer\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Run our data through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Provide a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gold labels = human labels of the input data\n",
    "* predicted labels = labels predicted by the model\n",
    "\n",
    "* True positive (TP) = predicted positive and gold positive\n",
    "* False positive (FP) = predicted positive and gold negative (Type I error)\n",
    "* True negative (TN) = predicted negative and gold negative \n",
    "* False negative (FN) = predicted negative and gold positive (Type II error)\n",
    "\n",
    "* precision = $\\frac{TP}{TP + FP}$\n",
    "* recall = $\\frac{TP}{TP + FN}$\n",
    "* F1 or F-measure = $F\\beta \\frac{(\\beta^2 + 1)\\times precision \\times recall}{\\beta^2 precision + recall}$\n",
    "* accuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Deep Dive into SKlearn Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MultinomialNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TFIDFVectorizer\n",
    "\n",
    "TFIDFVectorizer??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
