{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c768b3d8-aa8e-4915-855d-40d54862f708",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JamesMTucker/DATA_340_NLP/blob/master/Notebooks/Lecture_05_2023_02_09.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d97a68-4310-43a1-b088-3fa2030bb842",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lecture 04: Statistics and Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cfaaf-c78b-48f0-9eb3-8ab09d67a913",
   "metadata": {},
   "source": [
    "In the previous lecture, we examined some general statistical features of words and/or tokens. We observed that there the frequency of terms in document follow a power law distribution. We noticed that the most frequent words are often words that are hardly germane to the ideas of the text. What is more, we often don't think about ideas as associated with one word, but we can create noun phrases or prepositional phrases to communicate our ideas. For example, the phrase \"bacon and eggs\" might mean, in a given context, the entities to which the words are referencing. In a different context, however, the noun phrase, \"bacon and eggs\", could mean the event of breakfast or the items one would prefer to eat at the event of a morning meal. Thus, we need a strategy to assess the co-occurrence of n-terms and whether the co-occurence is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b2b39-bbad-4011-8f32-5433286357ca",
   "metadata": {},
   "source": [
    "## Let's look the LOTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf504c-bc9a-4864-be6f-79d66a659201",
   "metadata": {},
   "source": [
    "Q: What do you think is most frequently occuring group of two words or tokens in the Lord of the Rings? Do think the answer provides insight into the theme(s) or topic(s) of the story? What do we expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b952af4c-873c-407e-b9d0-f42c1ddf9a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets import some packages and configure our notebook\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916b79a-60e7-4f2b-ac0d-2fe22de95dbe",
   "metadata": {},
   "source": [
    "N.B.: Comment out the below and run the colab block if you are working in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6b1da5-b30a-442b-a0e3-da93d10d3efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the Lord of the Rings text\n",
    "files = Path('./data/').glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da31a1e0-396d-456b-ae06-8c3d49a57943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Google colab, uncomment this line of code and run\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/', force_remount=True)\n",
    "# files = Path('gdrive/MyDrive/DATA_340_3_NLP/Datasets').glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "839bf5d2-9ffd-4172-9218-03dd416dc205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the text of the _The Fellowship of the Ring_ so let's extract it from our files\n",
    "fellowship = \"\"\n",
    "\n",
    "for f in files:\n",
    "    # Parse the file name using the os package\n",
    "    base_name = os.path.basename(f)\n",
    "    f_name, _ = os.path.splitext(base_name)\n",
    "    \n",
    "    # We are only concerned with the Fellowship\n",
    "    if not f_name == '01_LOTR_Fellowship':\n",
    "        continue\n",
    "    else:\n",
    "        with open(f, 'r', encoding=\"utf-8\") as FIN:\n",
    "            fellowship = FIN.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d3a98-b44f-4086-b0bc-d6632eaf21dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's Tokenize, Lemmatize, and Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b05d936-e8ec-4e0c-93ca-580f1e747ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can use NLTK to tokenize and lemmatize our text\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Create instances of the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# For stopwords we will add punctuation\n",
    "punct = list(string.punctuation) + list(string.digits)\n",
    "stop_words = stopwords.words('english') + punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb33922e-fb3a-41fb-a6e0-9e6d6f0a4228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty list to append the tokens and not stopwords\n",
    "lemmas = []\n",
    "\n",
    "# Iterate over the text to extract our lemmas\n",
    "def tokenize_lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            lemmas.append(stemmer.stem(token))\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f592c26-208b-415d-8819-76daec0c1fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass our text to the above function so we can then create a bigram dictionary\n",
    "fellowship_token_lemmas = tokenize_lemmatize_text(fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0680b404-e196-4848-999b-8fa2d0a4cb73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three',\n",
       " 'ring',\n",
       " 'elven-k',\n",
       " 'sky',\n",
       " 'seven',\n",
       " 'dwarf-lord',\n",
       " 'hall',\n",
       " 'stone',\n",
       " 'nine',\n",
       " 'mortal',\n",
       " 'men',\n",
       " 'doom',\n",
       " 'die',\n",
       " 'one',\n",
       " 'dark',\n",
       " 'lord',\n",
       " 'dark',\n",
       " 'throne',\n",
       " 'in',\n",
       " 'land',\n",
       " 'mordor',\n",
       " 'shadow',\n",
       " 'lie',\n",
       " 'one',\n",
       " 'ring',\n",
       " 'rule',\n",
       " 'one',\n",
       " 'ring',\n",
       " 'find',\n",
       " 'one',\n",
       " 'ring',\n",
       " 'bring',\n",
       " 'dark',\n",
       " 'bind',\n",
       " 'in',\n",
       " 'land',\n",
       " 'mordor',\n",
       " 'shadow',\n",
       " 'lie',\n",
       " 'foreword',\n",
       " 'thi',\n",
       " 'tale',\n",
       " 'grew',\n",
       " 'tell',\n",
       " 'becam',\n",
       " 'histori',\n",
       " 'great',\n",
       " 'war',\n",
       " 'ring',\n",
       " 'includ',\n",
       " 'mani',\n",
       " 'glimps',\n",
       " 'yet',\n",
       " 'ancient',\n",
       " 'histori',\n",
       " 'preced',\n",
       " 'it',\n",
       " 'begun',\n",
       " 'soon',\n",
       " '_the',\n",
       " 'hobbit_',\n",
       " 'written',\n",
       " 'public',\n",
       " '1937',\n",
       " 'i',\n",
       " 'go',\n",
       " 'sequel',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'first',\n",
       " 'complet',\n",
       " 'set',\n",
       " 'order',\n",
       " 'mytholog',\n",
       " 'legend',\n",
       " 'elder',\n",
       " 'day',\n",
       " 'take',\n",
       " 'shape',\n",
       " 'year',\n",
       " 'i',\n",
       " 'desir',\n",
       " 'satisfact',\n",
       " 'i',\n",
       " 'littl',\n",
       " 'hope',\n",
       " 'peopl',\n",
       " 'would',\n",
       " 'interest',\n",
       " 'work',\n",
       " 'especi',\n",
       " 'sinc',\n",
       " 'primarili',\n",
       " 'linguist',\n",
       " 'inspir',\n",
       " 'begun',\n",
       " 'order',\n",
       " 'provid',\n",
       " 'necessari',\n",
       " 'background',\n",
       " \"'histori\",\n",
       " 'elvish',\n",
       " 'tongu',\n",
       " 'when',\n",
       " 'whose',\n",
       " 'advic',\n",
       " 'opinion',\n",
       " 'i',\n",
       " 'sought',\n",
       " 'correct',\n",
       " '_littl',\n",
       " 'hope_',\n",
       " '_no',\n",
       " 'hope',\n",
       " 'i',\n",
       " 'went',\n",
       " 'back',\n",
       " 'sequel',\n",
       " 'encourag',\n",
       " 'request',\n",
       " 'reader',\n",
       " 'inform',\n",
       " 'concern',\n",
       " 'hobbit',\n",
       " 'adventur',\n",
       " 'but',\n",
       " 'stori',\n",
       " 'drawn',\n",
       " 'irresist',\n",
       " 'toward',\n",
       " 'older',\n",
       " 'world',\n",
       " 'becam',\n",
       " 'account',\n",
       " 'end',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'begin',\n",
       " 'middl',\n",
       " 'told',\n",
       " 'the',\n",
       " 'process',\n",
       " 'begun',\n",
       " 'write',\n",
       " '_the',\n",
       " 'hobbit',\n",
       " 'alreadi',\n",
       " 'refer',\n",
       " 'older',\n",
       " 'matter',\n",
       " 'elrond',\n",
       " 'gondolin',\n",
       " 'high-elv',\n",
       " 'orc',\n",
       " 'well',\n",
       " 'glimps',\n",
       " 'arisen',\n",
       " 'unbidden',\n",
       " 'thing',\n",
       " 'higher',\n",
       " 'deeper',\n",
       " 'darker',\n",
       " 'surfac',\n",
       " 'durin',\n",
       " 'moria',\n",
       " 'gandalf',\n",
       " 'necromanc',\n",
       " 'ring',\n",
       " 'the',\n",
       " 'discoveri',\n",
       " 'signific',\n",
       " 'glimps',\n",
       " 'relat',\n",
       " 'ancient',\n",
       " 'histori',\n",
       " 'reveal',\n",
       " 'third',\n",
       " 'age',\n",
       " 'culmin',\n",
       " 'war',\n",
       " 'ring',\n",
       " 'those',\n",
       " 'ask',\n",
       " 'inform',\n",
       " 'hobbit',\n",
       " 'eventu',\n",
       " 'got',\n",
       " 'wait',\n",
       " 'long',\n",
       " 'time',\n",
       " 'composit',\n",
       " '_the',\n",
       " 'lord',\n",
       " 'rings_',\n",
       " 'went',\n",
       " 'interv',\n",
       " 'year',\n",
       " '1936',\n",
       " '1949',\n",
       " 'period',\n",
       " 'i',\n",
       " 'mani',\n",
       " 'duti',\n",
       " 'i',\n",
       " 'neglect',\n",
       " 'mani',\n",
       " 'interest',\n",
       " 'learner',\n",
       " 'teacher',\n",
       " 'often',\n",
       " 'absorb',\n",
       " 'the',\n",
       " 'delay',\n",
       " 'cours',\n",
       " 'also',\n",
       " 'increas',\n",
       " 'outbreak',\n",
       " 'war',\n",
       " '1939',\n",
       " 'end',\n",
       " 'year',\n",
       " 'tale',\n",
       " 'yet',\n",
       " 'reach',\n",
       " 'end',\n",
       " 'book',\n",
       " 'one',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'dark',\n",
       " 'next',\n",
       " 'five',\n",
       " 'year',\n",
       " 'i',\n",
       " 'found',\n",
       " 'stori',\n",
       " 'could',\n",
       " 'wholli',\n",
       " 'abandon',\n",
       " 'i',\n",
       " 'plod',\n",
       " 'mostli',\n",
       " 'night',\n",
       " 'till',\n",
       " 'i',\n",
       " 'stood',\n",
       " 'balin',\n",
       " \"'s\",\n",
       " 'tomb',\n",
       " 'moria',\n",
       " 'there',\n",
       " 'i',\n",
       " 'halt',\n",
       " 'long',\n",
       " 'it',\n",
       " 'almost',\n",
       " 'year',\n",
       " 'later',\n",
       " 'i',\n",
       " 'went',\n",
       " 'came',\n",
       " 'lothlórien',\n",
       " 'great',\n",
       " 'river',\n",
       " 'late',\n",
       " '1941',\n",
       " 'in',\n",
       " 'next',\n",
       " 'year',\n",
       " 'i',\n",
       " 'wrote',\n",
       " 'first',\n",
       " 'draft',\n",
       " 'matter',\n",
       " 'stand',\n",
       " 'book',\n",
       " 'three',\n",
       " 'begin',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'iii',\n",
       " 'book',\n",
       " 'five',\n",
       " 'beacon',\n",
       " 'flare',\n",
       " 'anórien',\n",
       " 'théoden',\n",
       " 'came',\n",
       " 'harrowdal',\n",
       " 'i',\n",
       " 'stop',\n",
       " 'foresight',\n",
       " 'fail',\n",
       " 'time',\n",
       " 'thought',\n",
       " 'it',\n",
       " '1944',\n",
       " 'leav',\n",
       " 'loos',\n",
       " 'end',\n",
       " 'perplex',\n",
       " 'war',\n",
       " 'task',\n",
       " 'conduct',\n",
       " 'least',\n",
       " 'report',\n",
       " 'forc',\n",
       " 'tackl',\n",
       " 'journey',\n",
       " 'frodo',\n",
       " 'mordor',\n",
       " 'these',\n",
       " 'chapter',\n",
       " 'eventu',\n",
       " 'becom',\n",
       " 'book',\n",
       " 'four',\n",
       " 'written',\n",
       " 'sent',\n",
       " 'serial',\n",
       " 'son',\n",
       " 'christoph',\n",
       " 'south',\n",
       " 'africa',\n",
       " 'raf',\n",
       " 'nonetheless',\n",
       " 'took',\n",
       " 'anoth',\n",
       " 'five',\n",
       " 'year',\n",
       " 'tale',\n",
       " 'brought',\n",
       " 'present',\n",
       " 'end',\n",
       " 'time',\n",
       " 'i',\n",
       " 'chang',\n",
       " 'hous',\n",
       " 'chair',\n",
       " 'colleg',\n",
       " 'day',\n",
       " 'though',\n",
       " 'less',\n",
       " 'dark',\n",
       " 'less',\n",
       " 'labori',\n",
       " 'then',\n",
       " \"'end\",\n",
       " 'last',\n",
       " 'reach',\n",
       " 'whole',\n",
       " 'stori',\n",
       " 'revis',\n",
       " 'inde',\n",
       " 'larg',\n",
       " 're-written',\n",
       " 'backward',\n",
       " 'and',\n",
       " 'type',\n",
       " 're-typ',\n",
       " 'cost',\n",
       " 'profession',\n",
       " 'type',\n",
       " 'ten-fing',\n",
       " 'beyond',\n",
       " 'mean',\n",
       " '_the',\n",
       " 'lord',\n",
       " 'rings_',\n",
       " 'read',\n",
       " 'mani',\n",
       " 'peopl',\n",
       " 'sinc',\n",
       " 'final',\n",
       " 'appear',\n",
       " 'print',\n",
       " 'i',\n",
       " 'like',\n",
       " 'say',\n",
       " 'someth',\n",
       " 'refer',\n",
       " 'mani',\n",
       " 'opinion',\n",
       " 'guess',\n",
       " 'i',\n",
       " 'receiv',\n",
       " 'read',\n",
       " 'concern',\n",
       " 'motiv',\n",
       " 'mean',\n",
       " 'tale',\n",
       " 'the',\n",
       " 'prime',\n",
       " 'motiv',\n",
       " 'desir',\n",
       " 'tale-tel',\n",
       " 'tri',\n",
       " 'hand',\n",
       " 'realli',\n",
       " 'long',\n",
       " 'stori',\n",
       " 'would',\n",
       " 'hold',\n",
       " 'attent',\n",
       " 'reader',\n",
       " 'amus',\n",
       " 'delight',\n",
       " 'time',\n",
       " 'mayb',\n",
       " 'excit',\n",
       " 'deepli',\n",
       " 'move',\n",
       " 'as',\n",
       " 'guid',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'appeal',\n",
       " 'move',\n",
       " 'mani',\n",
       " 'guid',\n",
       " 'inevit',\n",
       " 'often',\n",
       " 'fault',\n",
       " 'some',\n",
       " 'read',\n",
       " 'book',\n",
       " 'rate',\n",
       " 'review',\n",
       " 'found',\n",
       " 'bore',\n",
       " 'absurd',\n",
       " 'contempt',\n",
       " 'i',\n",
       " 'caus',\n",
       " 'complain',\n",
       " 'sinc',\n",
       " 'i',\n",
       " 'similar',\n",
       " 'opinion',\n",
       " 'work',\n",
       " 'kind',\n",
       " 'write',\n",
       " 'evid',\n",
       " 'prefer',\n",
       " 'but',\n",
       " 'even',\n",
       " 'point',\n",
       " 'view',\n",
       " 'mani',\n",
       " 'enjoy',\n",
       " 'stori',\n",
       " 'much',\n",
       " 'fail',\n",
       " 'pleas',\n",
       " 'it',\n",
       " 'perhap',\n",
       " 'possibl',\n",
       " 'long',\n",
       " 'tale',\n",
       " 'pleas',\n",
       " 'everybodi',\n",
       " 'point',\n",
       " 'displeas',\n",
       " 'everybodi',\n",
       " 'point',\n",
       " 'i',\n",
       " 'find',\n",
       " 'letter',\n",
       " 'i',\n",
       " 'receiv',\n",
       " 'passag',\n",
       " 'chapter',\n",
       " 'blemish',\n",
       " 'other',\n",
       " 'special',\n",
       " 'approv',\n",
       " 'the',\n",
       " 'critic',\n",
       " 'reader',\n",
       " 'find',\n",
       " 'mani',\n",
       " 'defect',\n",
       " 'minor',\n",
       " 'major',\n",
       " 'fortun',\n",
       " 'oblig',\n",
       " 'either',\n",
       " 'review',\n",
       " 'book',\n",
       " 'write',\n",
       " 'pass',\n",
       " 'silenc',\n",
       " 'except',\n",
       " 'one',\n",
       " 'note',\n",
       " 'other',\n",
       " 'book',\n",
       " 'short',\n",
       " 'as',\n",
       " 'inner',\n",
       " 'mean',\n",
       " \"'messag\",\n",
       " 'intent',\n",
       " 'author',\n",
       " 'none',\n",
       " 'it',\n",
       " 'neither',\n",
       " 'allegor',\n",
       " 'topic',\n",
       " 'as',\n",
       " 'stori',\n",
       " 'grew',\n",
       " 'put',\n",
       " 'root',\n",
       " 'past',\n",
       " 'threw',\n",
       " 'unexpect',\n",
       " 'branch',\n",
       " 'main',\n",
       " 'theme',\n",
       " 'settl',\n",
       " 'outset',\n",
       " 'inevit',\n",
       " 'choic',\n",
       " 'ring',\n",
       " 'link',\n",
       " '_the',\n",
       " 'hobbit._',\n",
       " 'the',\n",
       " 'crucial',\n",
       " 'chapter',\n",
       " '``',\n",
       " 'the',\n",
       " 'shadow',\n",
       " 'past',\n",
       " 'one',\n",
       " 'oldest',\n",
       " 'part',\n",
       " 'tale',\n",
       " 'it',\n",
       " 'written',\n",
       " 'long',\n",
       " 'foreshadow',\n",
       " '1939',\n",
       " 'yet',\n",
       " 'becom',\n",
       " 'threat',\n",
       " 'inevit',\n",
       " 'disast',\n",
       " 'point',\n",
       " 'stori',\n",
       " 'would',\n",
       " 'develop',\n",
       " 'along',\n",
       " 'essenti',\n",
       " 'line',\n",
       " 'disast',\n",
       " 'avert',\n",
       " 'it',\n",
       " 'sourc',\n",
       " 'thing',\n",
       " 'long',\n",
       " 'mind',\n",
       " 'case',\n",
       " 'alreadi',\n",
       " 'written',\n",
       " 'littl',\n",
       " 'noth',\n",
       " 'modifi',\n",
       " 'war',\n",
       " 'began',\n",
       " '1939',\n",
       " 'sequel',\n",
       " 'the',\n",
       " 'real',\n",
       " 'war',\n",
       " 'resembl',\n",
       " 'legendari',\n",
       " 'war',\n",
       " 'process',\n",
       " 'conclus',\n",
       " 'if',\n",
       " 'inspir',\n",
       " 'direct',\n",
       " 'develop',\n",
       " 'legend',\n",
       " 'certainli',\n",
       " 'ring',\n",
       " 'would',\n",
       " 'seiz',\n",
       " 'use',\n",
       " 'sauron',\n",
       " 'would',\n",
       " 'annihil',\n",
       " 'enslav',\n",
       " 'barad-dûr',\n",
       " 'would',\n",
       " 'destroy',\n",
       " 'occupi',\n",
       " 'saruman',\n",
       " 'fail',\n",
       " 'get',\n",
       " 'possess',\n",
       " 'ring',\n",
       " 'would',\n",
       " 'confus',\n",
       " 'treacheri',\n",
       " 'time',\n",
       " 'found',\n",
       " 'mordor',\n",
       " 'miss',\n",
       " 'link',\n",
       " 'research',\n",
       " 'ring-lor',\n",
       " 'long',\n",
       " 'would',\n",
       " 'made',\n",
       " 'great',\n",
       " 'ring',\n",
       " 'challeng',\n",
       " 'self-styl',\n",
       " 'ruler',\n",
       " 'middle-earth',\n",
       " 'in',\n",
       " 'conflict',\n",
       " 'side',\n",
       " 'would',\n",
       " 'held',\n",
       " 'hobbit',\n",
       " 'hatr',\n",
       " 'contempt',\n",
       " 'would',\n",
       " 'long',\n",
       " 'surviv',\n",
       " 'even',\n",
       " 'slave',\n",
       " 'other',\n",
       " 'arrang',\n",
       " 'could',\n",
       " 'devis',\n",
       " 'accord',\n",
       " 'tast',\n",
       " 'view',\n",
       " 'like',\n",
       " 'allegori',\n",
       " 'topic',\n",
       " 'refer',\n",
       " 'but',\n",
       " 'i',\n",
       " 'cordial',\n",
       " 'dislik',\n",
       " 'allegori',\n",
       " 'manifest',\n",
       " 'alway',\n",
       " 'done',\n",
       " 'sinc',\n",
       " 'i',\n",
       " 'grew',\n",
       " 'old',\n",
       " 'wari',\n",
       " 'enough',\n",
       " 'detect',\n",
       " 'presenc',\n",
       " 'i',\n",
       " 'much',\n",
       " 'prefer',\n",
       " 'histori',\n",
       " 'true',\n",
       " 'feign',\n",
       " 'vari',\n",
       " 'applic',\n",
       " 'thought',\n",
       " 'experi',\n",
       " 'reader',\n",
       " 'i',\n",
       " 'think',\n",
       " 'mani',\n",
       " 'confus',\n",
       " \"'applic\",\n",
       " \"'allegori\",\n",
       " 'one',\n",
       " 'resid',\n",
       " 'freedom',\n",
       " 'reader',\n",
       " 'purpos',\n",
       " 'domin',\n",
       " 'author',\n",
       " 'an',\n",
       " 'author',\n",
       " 'cours',\n",
       " 'remain',\n",
       " 'wholli',\n",
       " 'unaffect',\n",
       " 'experi',\n",
       " 'way',\n",
       " 'story-germ',\n",
       " 'use',\n",
       " 'soil',\n",
       " 'experi',\n",
       " 'extrem',\n",
       " 'complex',\n",
       " 'attempt',\n",
       " 'defin',\n",
       " 'process',\n",
       " 'best',\n",
       " 'guess',\n",
       " 'evid',\n",
       " 'inadequ',\n",
       " 'ambigu',\n",
       " 'it',\n",
       " 'also',\n",
       " 'fals',\n",
       " 'though',\n",
       " 'natur',\n",
       " 'attract',\n",
       " 'live',\n",
       " 'author',\n",
       " 'critic',\n",
       " 'overlap',\n",
       " 'suppos',\n",
       " 'movement',\n",
       " 'thought',\n",
       " 'event',\n",
       " 'time',\n",
       " 'common',\n",
       " 'necessarili',\n",
       " 'power',\n",
       " 'influenc',\n",
       " 'one',\n",
       " 'inde',\n",
       " 'person',\n",
       " 'come',\n",
       " 'shadow',\n",
       " 'war',\n",
       " 'feel',\n",
       " 'fulli',\n",
       " 'oppress',\n",
       " 'year',\n",
       " 'go',\n",
       " 'seem',\n",
       " 'often',\n",
       " 'forgotten',\n",
       " 'caught',\n",
       " 'youth',\n",
       " '1914',\n",
       " 'less',\n",
       " 'hideou',\n",
       " 'experi',\n",
       " 'involv',\n",
       " '1939',\n",
       " 'follow',\n",
       " 'year',\n",
       " 'by',\n",
       " '1918',\n",
       " 'one',\n",
       " 'close',\n",
       " 'friend',\n",
       " 'dead',\n",
       " 'or',\n",
       " 'take',\n",
       " 'less',\n",
       " 'grievou',\n",
       " 'matter',\n",
       " 'suppos',\n",
       " \"'the\",\n",
       " 'scour',\n",
       " 'shire',\n",
       " 'reflect',\n",
       " 'situat',\n",
       " 'england',\n",
       " 'time',\n",
       " 'i',\n",
       " 'finish',\n",
       " 'tale',\n",
       " 'it',\n",
       " 'it',\n",
       " 'essenti',\n",
       " 'part',\n",
       " 'plot',\n",
       " 'foreseen',\n",
       " 'outset',\n",
       " 'though',\n",
       " 'event',\n",
       " 'modifi',\n",
       " 'charact',\n",
       " 'saruman',\n",
       " 'develop',\n",
       " 'stori',\n",
       " 'without',\n",
       " 'need',\n",
       " 'i',\n",
       " 'say',\n",
       " 'allegor',\n",
       " 'signific',\n",
       " 'contemporari',\n",
       " 'polit',\n",
       " 'refer',\n",
       " 'whatsoev',\n",
       " 'it',\n",
       " 'inde',\n",
       " 'basi',\n",
       " 'experi',\n",
       " 'though',\n",
       " 'slender',\n",
       " 'econom',\n",
       " 'situat',\n",
       " 'entir',\n",
       " 'differ',\n",
       " 'much',\n",
       " 'back',\n",
       " 'the',\n",
       " 'countri',\n",
       " 'i',\n",
       " 'live',\n",
       " 'childhood',\n",
       " 'shabbili',\n",
       " 'destroy',\n",
       " 'i',\n",
       " 'ten',\n",
       " 'day',\n",
       " 'motor-car',\n",
       " 'rare',\n",
       " 'object',\n",
       " 'i',\n",
       " 'never',\n",
       " 'seen',\n",
       " 'one',\n",
       " 'men',\n",
       " 'still',\n",
       " 'build',\n",
       " 'suburban',\n",
       " 'railway',\n",
       " 'recent',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'paper',\n",
       " 'pictur',\n",
       " 'last',\n",
       " 'decrepitud',\n",
       " 'thrive',\n",
       " 'corn-mil',\n",
       " 'besid',\n",
       " 'pool',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'seem',\n",
       " 'import',\n",
       " 'i',\n",
       " 'never',\n",
       " 'like',\n",
       " 'look',\n",
       " 'young',\n",
       " 'miller',\n",
       " 'father',\n",
       " 'old',\n",
       " 'miller',\n",
       " 'black',\n",
       " 'beard',\n",
       " 'name',\n",
       " 'sandyman',\n",
       " '_the',\n",
       " 'lord',\n",
       " 'rings_',\n",
       " 'issu',\n",
       " 'new',\n",
       " 'edit',\n",
       " 'opportun',\n",
       " 'taken',\n",
       " 'revis',\n",
       " 'a',\n",
       " 'number',\n",
       " 'error',\n",
       " 'inconsist',\n",
       " 'still',\n",
       " 'remain',\n",
       " 'text',\n",
       " 'correct',\n",
       " 'attempt',\n",
       " 'made',\n",
       " 'provid',\n",
       " 'inform',\n",
       " 'point',\n",
       " 'attent',\n",
       " 'reader',\n",
       " 'rais',\n",
       " 'i',\n",
       " 'consid',\n",
       " 'comment',\n",
       " 'enquiri',\n",
       " 'seem',\n",
       " 'pass',\n",
       " 'may',\n",
       " 'i',\n",
       " 'fail',\n",
       " 'keep',\n",
       " 'note',\n",
       " 'order',\n",
       " 'mani',\n",
       " 'enquiri',\n",
       " 'could',\n",
       " 'answer',\n",
       " 'addit',\n",
       " 'appendic',\n",
       " 'inde',\n",
       " 'product',\n",
       " 'accessori',\n",
       " 'volum',\n",
       " 'contain',\n",
       " 'much',\n",
       " 'materi',\n",
       " 'i',\n",
       " 'includ',\n",
       " 'origin',\n",
       " 'edit',\n",
       " 'particular',\n",
       " 'detail',\n",
       " 'linguist',\n",
       " 'inform',\n",
       " 'in',\n",
       " 'meantim',\n",
       " 'edit',\n",
       " 'offer',\n",
       " 'foreword',\n",
       " 'addit',\n",
       " 'prologu',\n",
       " 'note',\n",
       " 'index',\n",
       " 'name',\n",
       " 'person',\n",
       " 'place',\n",
       " 'thi',\n",
       " 'index',\n",
       " 'intent',\n",
       " 'complet',\n",
       " 'item',\n",
       " 'refer',\n",
       " 'sinc',\n",
       " 'present',\n",
       " 'purpos',\n",
       " 'necessari',\n",
       " 'reduc',\n",
       " 'bulk',\n",
       " 'a',\n",
       " 'complet',\n",
       " 'index',\n",
       " 'make',\n",
       " 'full',\n",
       " 'use',\n",
       " 'materi',\n",
       " 'prepar',\n",
       " 'mrs.',\n",
       " 'n.',\n",
       " 'smith',\n",
       " 'belong',\n",
       " 'rather',\n",
       " 'accessori',\n",
       " 'volum',\n",
       " 'prologu',\n",
       " 'thi',\n",
       " 'book',\n",
       " 'larg',\n",
       " 'concern',\n",
       " 'hobbit',\n",
       " 'page',\n",
       " 'reader',\n",
       " 'may',\n",
       " 'discov',\n",
       " 'much',\n",
       " 'charact',\n",
       " 'littl',\n",
       " 'histori',\n",
       " 'further',\n",
       " 'inform',\n",
       " 'also',\n",
       " 'found',\n",
       " 'select',\n",
       " 'red',\n",
       " 'book',\n",
       " 'westmarch',\n",
       " 'alreadi',\n",
       " 'publish',\n",
       " 'titl',\n",
       " '_the',\n",
       " 'hobbit_',\n",
       " 'that',\n",
       " 'stori',\n",
       " 'deriv',\n",
       " 'earlier',\n",
       " 'chapter',\n",
       " 'red',\n",
       " 'book',\n",
       " 'compos',\n",
       " 'bilbo',\n",
       " 'first',\n",
       " 'hobbit',\n",
       " 'becom',\n",
       " 'famou',\n",
       " 'world',\n",
       " 'larg',\n",
       " 'call',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fellowship_token_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1401cbc-42a7-48ea-816d-26983c8bdeea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's build a bi-token dictionary\n",
    "bigram_freqs = {}\n",
    "\n",
    "# List comprehension to create a list of bigrams\n",
    "bigrams = [(fellowship_token_lemmas[i], fellowship_token_lemmas[i + 1]) for i in range(len(fellowship_token_lemmas) - 1)]\n",
    "\n",
    "# The bigrams are repeated so we want to count the frequency of terms\n",
    "for bigram in bigrams:\n",
    "    bigram_freqs[bigram] = bigram_freqs.get(bigram, 0) + 1\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ecf2f8-645d-41d4-b915-fa836b83f932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigrams_sorted = list(sorted(bigram_freqs.items(), key=lambda kv: -kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ed23f57-e425-4489-a6be-a3849504f262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's create a dataframe of the bigrams using pandas\n",
    "import pandas as pd\n",
    "\n",
    "# to create the dataframe we need to use pd.DataFrame and pass it our data and give it some column names\n",
    "df = pd.DataFrame(bigrams_sorted, columns=['bigram', 'freq'])\n",
    "\n",
    "# Let's expand the bigrams to their own columns and keep the index so we can retain the frequencies\n",
    "df[['first_term', 'second_term']] = pd.DataFrame(df['bigram'].tolist(), index=df.index)\n",
    "\n",
    "# And drop the bigram column since we now have the lemmas in their own columns\n",
    "df = df.drop(columns=['bigram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27b245e6-e5f8-4e20-b25a-0fab89694cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>first_term</th>\n",
       "      <th>second_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>said</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>i</td>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135</td>\n",
       "      <td>said</td>\n",
       "      <td>gandalf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>i</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>but</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76555</th>\n",
       "      <td>1</td>\n",
       "      <td>ring-bear</td>\n",
       "      <td>in_th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76556</th>\n",
       "      <td>1</td>\n",
       "      <td>in_th</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76557</th>\n",
       "      <td>1</td>\n",
       "      <td>return</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76558</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76559</th>\n",
       "      <td>1</td>\n",
       "      <td>king</td>\n",
       "      <td>==============================================...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq first_term                                        second_term\n",
       "0       220       said                                              frodo\n",
       "1       138          i                                                n't\n",
       "2       135       said                                            gandalf\n",
       "3       109          i                                              think\n",
       "4        93        but                                                  i\n",
       "...     ...        ...                                                ...\n",
       "76555     1  ring-bear                                              in_th\n",
       "76556     1      in_th                                             return\n",
       "76557     1     return                                                 of\n",
       "76558     1        the                                               king\n",
       "76559     1       king  ==============================================...\n",
       "\n",
       "[76560 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "312617b9-cad8-4ce0-9b94-b05998ef66ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>first_term</th>\n",
       "      <th>second_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>frodo</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65</td>\n",
       "      <td>frodo</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>33</td>\n",
       "      <td>frodo</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>26</td>\n",
       "      <td>frodo</td>\n",
       "      <td>felt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>24</td>\n",
       "      <td>frodo</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76393</th>\n",
       "      <td>1</td>\n",
       "      <td>frodo</td>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76411</th>\n",
       "      <td>1</td>\n",
       "      <td>frodo</td>\n",
       "      <td>actual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76439</th>\n",
       "      <td>1</td>\n",
       "      <td>frodo</td>\n",
       "      <td>laid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76466</th>\n",
       "      <td>1</td>\n",
       "      <td>frodo</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76470</th>\n",
       "      <td>1</td>\n",
       "      <td>frodo</td>\n",
       "      <td>paddl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq first_term second_term\n",
       "8        66      frodo          's\n",
       "9        65      frodo           i\n",
       "53       33      frodo        look\n",
       "68       26      frodo        felt\n",
       "86       24      frodo        said\n",
       "...     ...        ...         ...\n",
       "76393     1      frodo         n't\n",
       "76411     1      frodo      actual\n",
       "76439     1      frodo        laid\n",
       "76466     1      frodo          we\n",
       "76470     1      frodo       paddl\n",
       "\n",
       "[449 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"first_term == 'frodo'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5cc1ce8-5959-4e89-b348-e1a63f53f75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_frodo = df.query(\"second_term == 'frodo'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef8a5fd2-c19c-45b8-8ded-c4c45c194a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>first_term</th>\n",
       "      <th>second_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>said</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>ask</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>36</td>\n",
       "      <td>mr.</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>25</td>\n",
       "      <td>cri</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>19</td>\n",
       "      <td>look</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>1</td>\n",
       "      <td>choos</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75832</th>\n",
       "      <td>1</td>\n",
       "      <td>help</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76129</th>\n",
       "      <td>1</td>\n",
       "      <td>_frodo</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76354</th>\n",
       "      <td>1</td>\n",
       "      <td>water-rat</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76438</th>\n",
       "      <td>1</td>\n",
       "      <td>pile</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq first_term second_term\n",
       "0       220       said       frodo\n",
       "39       39        ask       frodo\n",
       "42       36        mr.       frodo\n",
       "80       25        cri       frodo\n",
       "117      19       look       frodo\n",
       "...     ...        ...         ...\n",
       "75817     1      choos       frodo\n",
       "75832     1       help       frodo\n",
       "76129     1     _frodo       frodo\n",
       "76354     1  water-rat       frodo\n",
       "76438     1       pile       frodo\n",
       "\n",
       "[488 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_frodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f63c3f3-3554-4889-82cc-0bc283e3e963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the frequencies to get the total count\n",
    "x_frodo.freq.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c98b5b-d7b3-4930-86c8-8d43cf1ef2a8",
   "metadata": {},
   "source": [
    "## Shannon's Entropy\n",
    "\n",
    "A lot of what we do with written communication is comparison. We as humans come to understand information and ideas through comparisons. The same is true for Natural Language Processing. We want to compare. An important metric for comparison and discerning similarity between things is Shannon's entropy.\n",
    "\n",
    "$$H(X) := -\\sum_{x\\in{X}} p(x) log p(x)$$\n",
    "\n",
    "We can make this more intuitive by rewriting it to describe surprise:\n",
    "\n",
    "$$\\sum{p(x)} log(\\frac{1}{\\frac{1}{p(x)}})$$\n",
    "\n",
    "As a statement of surprise, we can see that probability and surprise are inversely related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25f87b-8bb0-449c-b52c-527e9b126dd8",
   "metadata": {},
   "source": [
    "## We can use the scipy module to calculate entropy\n",
    "\n",
    "[Entropy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8844af-d5f5-4de6-9a4b-eb9e8c0c881b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's import the entropy function from scipy\n",
    "from scipy.stats import entropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01657ee5-0d0b-4ba6-829c-1c8d4c8b738a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'np.typing.ArrayLike'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[np.typing.ArrayLike]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[float]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Union[np.number, np.ndarray]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mqk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Calculate the Shannon entropy/relative entropy of given distribution(s).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    If only probabilities `pk` are given, the Shannon entropy is calculated as\u001b[0m\n",
       "\u001b[0;34m    ``H = -sum(pk * log(pk))``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    If `qk` is not None, then compute the relative entropy\u001b[0m\n",
       "\u001b[0;34m    ``D = sum(pk * log(pk / qk))``. This quantity is also known\u001b[0m\n",
       "\u001b[0;34m    as the Kullback-Leibler divergence.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This routine will normalize `pk` and `qk` if they don't sum to 1.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    pk : array_like\u001b[0m\n",
       "\u001b[0;34m        Defines the (discrete) distribution. Along each axis-slice of ``pk``,\u001b[0m\n",
       "\u001b[0;34m        element ``i`` is the  (possibly unnormalized) probability of event\u001b[0m\n",
       "\u001b[0;34m        ``i``.\u001b[0m\n",
       "\u001b[0;34m    qk : array_like, optional\u001b[0m\n",
       "\u001b[0;34m        Sequence against which the relative entropy is computed. Should be in\u001b[0m\n",
       "\u001b[0;34m        the same format as `pk`.\u001b[0m\n",
       "\u001b[0;34m    base : float, optional\u001b[0m\n",
       "\u001b[0;34m        The logarithmic base to use, defaults to ``e`` (natural logarithm).\u001b[0m\n",
       "\u001b[0;34m    axis : int, optional\u001b[0m\n",
       "\u001b[0;34m        The axis along which the entropy is calculated. Default is 0.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    S : {float, array_like}\u001b[0m\n",
       "\u001b[0;34m        The calculated entropy.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    Informally, the Shannon entropy quantifies the expected uncertainty\u001b[0m\n",
       "\u001b[0;34m    inherent in the possible outcomes of a discrete random variable.\u001b[0m\n",
       "\u001b[0;34m    For example,\u001b[0m\n",
       "\u001b[0;34m    if messages consisting of sequences of symbols from a set are to be\u001b[0m\n",
       "\u001b[0;34m    encoded and transmitted over a noiseless channel, then the Shannon entropy\u001b[0m\n",
       "\u001b[0;34m    ``H(pk)`` gives a tight lower bound for the average number of units of\u001b[0m\n",
       "\u001b[0;34m    information needed per symbol if the symbols occur with frequencies\u001b[0m\n",
       "\u001b[0;34m    governed by the discrete distribution `pk` [1]_. The choice of base\u001b[0m\n",
       "\u001b[0;34m    determines the choice of units; e.g., ``e`` for nats, ``2`` for bits, etc.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The relative entropy, ``D(pk|qk)``, quantifies the increase in the average\u001b[0m\n",
       "\u001b[0;34m    number of units of information needed per symbol if the encoding is\u001b[0m\n",
       "\u001b[0;34m    optimized for the probability distribution `qk` instead of the true\u001b[0m\n",
       "\u001b[0;34m    distribution `pk`. Informally, the relative entropy quantifies the expected\u001b[0m\n",
       "\u001b[0;34m    excess in surprise experienced if one believes the true distribution is\u001b[0m\n",
       "\u001b[0;34m    `qk` when it is actually `pk`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    A related quantity, the cross entropy ``CE(pk, qk)``, satisfies the\u001b[0m\n",
       "\u001b[0;34m    equation ``CE(pk, qk) = H(pk) + D(pk|qk)`` and can also be calculated with\u001b[0m\n",
       "\u001b[0;34m    the formula ``CE = -sum(pk * log(qk))``. It gives the average\u001b[0m\n",
       "\u001b[0;34m    number of units of information needed per symbol if an encoding is\u001b[0m\n",
       "\u001b[0;34m    optimized for the probability distribution `qk` when the true distribution\u001b[0m\n",
       "\u001b[0;34m    is `pk`. It is not computed directly by `entropy`, but it can be computed\u001b[0m\n",
       "\u001b[0;34m    using two calls to the function (see Examples).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See [2]_ for more information.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] Shannon, C.E. (1948), A Mathematical Theory of Communication.\u001b[0m\n",
       "\u001b[0;34m           Bell System Technical Journal, 27: 379-423.\u001b[0m\n",
       "\u001b[0;34m           https://doi.org/10.1002/j.1538-7305.1948.tb01338.x\u001b[0m\n",
       "\u001b[0;34m    .. [2] Thomas M. Cover and Joy A. Thomas. 2006. Elements of Information\u001b[0m\n",
       "\u001b[0;34m           Theory (Wiley Series in Telecommunications and Signal Processing).\u001b[0m\n",
       "\u001b[0;34m           Wiley-Interscience, USA.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    The outcome of a fair coin is the most uncertain:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from scipy.stats import entropy\u001b[0m\n",
       "\u001b[0;34m    >>> base = 2  # work in units of bits\u001b[0m\n",
       "\u001b[0;34m    >>> pk = np.array([1/2, 1/2])  # fair coin\u001b[0m\n",
       "\u001b[0;34m    >>> H = entropy(pk, base=base)\u001b[0m\n",
       "\u001b[0;34m    >>> H\u001b[0m\n",
       "\u001b[0;34m    1.0\u001b[0m\n",
       "\u001b[0;34m    >>> H == -np.sum(pk * np.log(pk)) / np.log(base)\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The outcome of a biased coin is less uncertain:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> qk = np.array([9/10, 1/10])  # biased coin\u001b[0m\n",
       "\u001b[0;34m    >>> entropy(qk, base=base)\u001b[0m\n",
       "\u001b[0;34m    0.46899559358928117\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The relative entropy between the fair coin and biased coin is calculated\u001b[0m\n",
       "\u001b[0;34m    as:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> D = entropy(pk, qk, base=base)\u001b[0m\n",
       "\u001b[0;34m    >>> D\u001b[0m\n",
       "\u001b[0;34m    0.7369655941662062\u001b[0m\n",
       "\u001b[0;34m    >>> D == np.sum(pk * np.log(pk/qk)) / np.log(base)\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The cross entropy can be calculated as the sum of the entropy and\u001b[0m\n",
       "\u001b[0;34m    relative entropy`:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> CE = entropy(pk, base=base) + entropy(pk, qk, base=base)\u001b[0m\n",
       "\u001b[0;34m    >>> CE\u001b[0m\n",
       "\u001b[0;34m    1.736965594166206\u001b[0m\n",
       "\u001b[0;34m    >>> CE == -np.sum(pk * np.log(qk)) / np.log(base)\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`base` must be a positive number or `None`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mqk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_entr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mS\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /media/james/Projects/GitHub/DATA_340_NLP/Notebooks/venv/lib/python3.10/site-packages/scipy/stats/_entropy.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Docs for entropy\n",
    "entropy??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13f97843-d693-4fe9-9fb0-15010d2025b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05565630554458895"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To understand the scipy code, think of the pk as the probabilities for the surprise of events, as defined above. The bigram (x, 'frodo') has a probability of 488/total bigrams.\n",
    "# To calculate the entropy of the bigram, we can plug in the probabilities for selecting the bigram (x, 'frodo') with the probabilities of not selecting (x, 'frodo'). \n",
    "# This gives us the entropy of the (x, 'frodo') bigram within the text of the Fellowship.\n",
    "\n",
    "base=2\n",
    "pk = np.array([488/76560, 76072/76560])\n",
    "entropy(pk, base=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1391c-2c9c-43f9-8317-4cb0fb173adc",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* Expected Values, Main Ideas!!! Directed by StatQuest with Josh Starmer, 2021. YouTube, https://www.youtube.com/watch?v=KLs_7b7SKi4.\n",
    "* Entropy (for Data Science) Clearly Explained!!! Directed by StatQuest with Josh Starmer, 2021. YouTube, https://www.youtube.com/watch?v=YtebGVx-Fxw.\n",
    "* Jurafsky and Martin, Chapter 3: [N-Gram Language Models](../course_readings/Jurafsky_Martin_chapter_3_39-65.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89a038-7263-4c66-9fc4-a8fe68ef4b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1626dfd1f59ab4e4380357488b4e73453692d701376229aa2051b38a01b9640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
