{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author prediction using RNNs\n",
    "\n",
    "In this notebook, you will prepare a dataset to predict authorship of the Federalist Papers using Recurrent Neural Networks (RNNs).\n",
    "\n",
    "## Federalist Papers\n",
    "\n",
    "The Federalist Papers are a collection of 85 articles and essays written by Alexander Hamilton, James Madison, and John Jay under the pseudonym \"Publius\". They were published in 1787 and 1788 to promote the ratification of the United States Constitution. The authors of the Federalist Papers wanted to remain anonymous, so they used the pseudonym \"Publius\". The articles were published in two newspapers, the New York Packet and the Independent Journal. The Federalist Papers are considered important works of American political thought and are still widely read today.\n",
    "\n",
    "## Additional information\n",
    "\n",
    "- [Federalist Papers](https://en.wikipedia.org/wiki/The_Federalist_Papers)\n",
    "- [Federalist Papers dataset](https://www.kaggle.com/datasets/tobyanderson/federalist-papers)\n",
    "- [LOC Research Guide](https://guides.loc.gov/federalist-papers/full-text)\n",
    "\n",
    "## Objectives (a)\n",
    "\n",
    "- Task 1: Design your dataset to predict the author of a text using RNNs.\n",
    "- Task 2: Explain the methodology of your dataset creation.\n",
    "- Task 3: Establish a baseline model using Machine Learning algorithms (SVM, Random Forest, etc.).\n",
    "  \n",
    "## Objectives (b)\n",
    "\n",
    "- Task 4: Train a RNN model to predict the author of a text.\n",
    "- Task 5: Evaluate the performance of your model.\n",
    "- Task 6: Explain your model architecture, hyperparameters, and the results of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "Use the below code to scrape the Library of Congress research guide for the Federalist Papers. You need to pip install the following for the below code to work:\n",
    "\n",
    "- `pip install beautifulsoup4`\n",
    "- `pip install requests`\n",
    "- `pip install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://guides.loc.gov/federalist-papers/full-text'\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# convert the html table to a pandas dataframe\n",
    "table = soup.find('table')\n",
    "\n",
    "# List of Federalist Papers\n",
    "meta_df = pd.read_html(StringIO(str(table)), parse_dates=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autorship counts\n",
    "\n",
    "Plot the count the number of papers written by each author. We want to create a machine learning dataset that consists of a train, validation, and test set. We will use the train set to train the model, the validation set to tune the hyperparameters, and the test set to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plot the number of papers written by each author\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='Author', data=meta_df)\n",
    "plt.title('Number of Papers Written by Each Author')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data, answer the following questions:\n",
    "\n",
    "- How many papers were written by each author?\n",
    "- How should you construct your dataset? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contested authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disputed papers\n",
    "disputed_papers = meta_df[meta_df['Author'] == 'Hamilton or Madison']\n",
    "contested_authorship = disputed_papers['No.'].values\n",
    "print(f'Contested authorship of papers: {contested_authorship}')\n",
    "print(f'Total number of disputed papers: {len(disputed_papers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Federalist Papers corpus\n",
    "\n",
    "The following code loads the Federalist Papers corpus. The papers have been preprocessed to aid your analysis of the authorship of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle('../datasets/Federalist_Papers/fp_corpus.pkl')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above datasets contains the following columns:\n",
    "\n",
    "- `paper_id`: The ID of the paper. This corresponds to the number of the paper in the Federalist Papers collection.\n",
    "- `author`: The author of the paper. This can be one of three values: `Hamilton`, `Madison`, `Jay`, `dispt` (disputed), and `HM` (Hamilton and Madison).\n",
    "- `text`: The text of the paper.\n",
    "- `sentence_length`: The token count of the sentence, defined as the number of tokens by splitting the sentence by spaces.\n",
    "- `sentence_index`: The index of the sentence in the paper.\n",
    "- `total_sentences`: The total number of sentences in the paper.\n",
    "\n",
    "The sentences were created by using the Spacy transformer library to split the text of papers into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates and keep target and paper_id\n",
    "authorship = corpus.drop_duplicates(subset=['paper_id', 'target'])\n",
    "authorship.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation\n",
    "\n",
    "Your task is to predict the author of a paper using the text of the paper. You will use a Recurrent Neural Network (RNN) to predict the author of a paper. You will use the Federalist Papers dataset to train and evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - CREATE A DATASET FOR THE CLASSIFICATION TASK OF AUTHORSHIP ATTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distribution of the number of papers written by each author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Visualize the distribution of the sentence lengths (what is the quartile distribution of the sentence lengths?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distribution of sentence lengths for each author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Visualize the distribution of sentence lengths according to the authorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training\n",
    "\n",
    "Prepare a training, validation, and test dataset. What is your X and y? What is the size of your training, validation, and test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_val, y_train, y_val = # YOUR CODE HERE\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Validation samples: {len(x_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# sample a random sentence from the training set\n",
    "random_idx = random.randint(0, len(X_train))\n",
    "print(f'Random sentence: {X_train.iloc[random_idx]}')\n",
    "print(f'Author: {y_train.iloc[random_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution of training and validation samples\n",
    "\n",
    "Have you split the dataset in a stratified manner? Explain why it is important to split the dataset in a stratified manner. If you have not, explain why you did not split the dataset in a stratified manner. See the documentation for [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the target classes in the training and validation set on a countplot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# first plot is the training set\n",
    "sns.countplot(y_train, ax=ax[0])\n",
    "ax[0].set_title('Training Set Distribution')\n",
    "# second plot is the validation set\n",
    "sns.countplot(y_val, ax=ax[1])\n",
    "ax[1].set_title('Validation Set Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the target labels to one hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "y_train_ohe = # YOUR CODE HERE\n",
    "y_val_ohe = # YOUR CODE HERE\n",
    "\n",
    "print(f'One hot encoded training labels shape: {y_train_ohe.shape}')\n",
    "print(f'One hot encoded validation labels shape: {y_val_ohe.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_le = # YOUR CODE HERE\n",
    "y_val_le = # YOUR CODE HERE\n",
    "\n",
    "print(f'Label encoded training labels shape: {y_train_le.shape}')\n",
    "print(f'Label encoded validation labels shape: {y_val_le.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'Original label: {y_train.iloc[i]} - Label encoded: {y_train_le[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC(kernel='linear', C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "# fit the model\n",
    "text_clf.fit(X_train, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.score(x_val, y_val_le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the TF-IDF model\n",
    "\n",
    "- What is the TF-IDF model?\n",
    "- How does the TF-IDF model work?\n",
    "- What are the hyperparameters of the TF-IDF model?\n",
    "- How do you select the hyperparameters of the TF-IDF model?\n",
    "- Why is it helpful to establish a baseline model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Train a Recurrent Neural Network (RNN) model\n",
    "\n",
    "In the second part of this assignment, you are tasked with the following:\n",
    "\n",
    "- Train a Recurrent Neural Network (RNN) model to predict the author of a paper.\n",
    "- Evaluate the performance of your model and compare it against the baseline model.\n",
    "- Explain your model architecture, hyperparameters, and the results of your model.\n",
    "- Discuss the challenges you faced during the model training process and how you overcame them.\n",
    "- Classify disputed papers using the Naive Bayes and RNN models\n",
    "- Write a summary of your findings and the predictions of your model with respect to the disputed papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize your text data\n",
    "\n",
    "Vectorize your text data with `tensorflow.keras.models.TextVectorization`. See the documentation here: [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import TextVectorization\n",
    "\n",
    "# YOUR CODE HERE - Create a TextVectorization layer - what arguments will you use? Explain your choice of arguments.\n",
    "\n",
    "text_vectorizer = TextVectorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly visualize some of your vectorized textual data\n",
    "import random\n",
    "example_sent = random.choice(X_train.values) # change var name if you need to\n",
    "print(f'Original text:\\n{example_sent}')\n",
    "print(f'\\nVectorized text:\\n{text_vectorizer([example_sent])}')\n",
    "print('Length of vector:', len(text_vectorizer([example_sent]).numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vocabulary\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "print(f'Number of words in the vocabulary: {len(vocab)}')\n",
    "print(f'Most common words in the vocabulary: {vocab[:5]}')\n",
    "print(f'Least common words in the vocabulary: {vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the config vars\n",
    "text_vectorizer.get_config() # when you train your model, these parameters can be changed to perhaps improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the text vectorizer to the training data\n",
    "text_vectorizer.adapt(YOUR_TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                            output_dim=128,\n",
    "                                            mask_zero=True,\n",
    "                                            name='token_embedding')\n",
    "\n",
    "print(f'Sentence before vectorization: {example_sent}')\n",
    "vectorized_sent = text_vectorizer(example_sent)\n",
    "print(f'Sentence after vectorization: {vectorized_sent}')\n",
    "embedded_sent = token_embedding(vectorized_sent)\n",
    "print(f'Sentence after embedding: {embedded_sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensorflow Dataset\n",
    "\n",
    "To efficiently train your model, you should create a `tf.data.Dataset` object. See the documentation here: [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = tf.data.Dataset.from_tensor_slices((YOUR CODE HERE))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((YOUR CODE HERE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 samples\n",
    "for sample in X_dataset.take(5):\n",
    "    sentence, label = sample\n",
    "    print(f'Sentence: {sentence} - Label: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches of data\n",
    "\n",
    "Batch size is a model hyperparameter that defines the number of samples that will be propagated through the network. This number can and should be adjusted in consideration with model performance and compute memory. See the documentation here: [Batch size](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = X_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: What does tf.data.AUTOTUNE do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = 'categorical_crossentropy'\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "inputs = tf.keras.layers.Inputs(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "# YOUR ADDITIONAL LAYERS HERE\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model or fit the model on the data\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: How can tensorflow automatically save the best performing model for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- QUESTION: Is your model overfit? Underfit?\n",
    "- QUESTION: Explain how bias and variance relate to training your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain your model architecture, hyperparameters, and the results of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- QUESTION: What hyperparameters resulted in the best performing model?\n",
    "- QUESTION: What parameters resulted in the best performing model?\n",
    "- QUESTION: What model architecture resulted in the best performing model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges faced during the model training process\n",
    "\n",
    "Please explain any challenges you faced and how you overcame them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the disputed authorship data\n",
    "\n",
    "Using the Naive Bayes and RNN models, classify the disputed author sentences. Use visuaulizations and confusion matrices to communicate the decision outputs of your models. Are there any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of your findings and predictions\n",
    "\n",
    "- Classify the undetermined sentences with the Naive Bayes Model and your RNN model. Compare and contrast the results.\n",
    "- What are your conclusions based on your experiments?\n",
    "- Describe how a data science NLP solution relates to other methdologies for addressing author identification. Can we and should we value the RNN outputs? How does our RNN solution relate to issues of human values, judgments, and biases of opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit\n",
    "\n",
    "Go back to your dataset creation and randomly change the author of the assigned sentence. With the labels randomized, rerun the code above. Describe what you learned in this process. (2pts to final grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed_papers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
