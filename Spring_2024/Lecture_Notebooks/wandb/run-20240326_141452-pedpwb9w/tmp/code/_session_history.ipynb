{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033007d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to generate data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042f4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate our data\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_redundant=15, n_informative=5, random_state=4)\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# Shape of the data\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce797565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tree depth values\n",
    "values = [i for i in range(1, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ed96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the decision tree model\n",
    "for i in values:\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=4)\n",
    "    \n",
    "    print(f\"[INFO] training model with max_depth = {i}\")\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    t_y_hat = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, t_y_hat)\n",
    "    train_scores.append(train_acc)\n",
    "    \n",
    "    # evaluate on the validation set\n",
    "    test_y_hat = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_y_hat)\n",
    "    test_scores.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06407002",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values, train_scores, '-o',  label=\"train\")\n",
    "plt.plot(values, test_scores, '-o', label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743d160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate some random data\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.randn(100) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3a25ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c52ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot data and model predictions\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.plot(X, model.predict(X_poly), color='red', linewidth=2)\n",
    "plt.title('Underfitting Linear Regression Model')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ebab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0e63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot data and model predictions\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.plot(X, model.predict(X_poly), color='red', linewidth=2)\n",
    "plt.title('Improved Linear Regression Model')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb097557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce4eb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source https://www.kaggle.com/code/robikscube/cross-validation-visualized-youtube-tutorial/notebook and Scikit-Learn documentation\n",
    "\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=25):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, 100],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv(cv, X, y, groups, n_splits=5):\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    plot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n",
    "\n",
    "    ax.legend(\n",
    "        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "        [\"Testing set\", \"Training set\"],\n",
    "        loc=(1.02, 0.8),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "def get_fake_X_y():\n",
    "    # Fake Generate the class/group data for an example\n",
    "    n_points = 100\n",
    "    X_ = np.random.randn(100, 10)\n",
    "\n",
    "    percentiles_classes = [0.1, 0.9]\n",
    "    y_ = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n",
    "\n",
    "    # Evenly spaced groups repeated once\n",
    "    groups_ = np.hstack([[ii] * 10 for ii in range(10)])\n",
    "    return X_, y_, groups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a4faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some sample data\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randint(0, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e73f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# create an instance of StratifiedKFold\n",
    "skf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# create an empty list to store the cross-validation scores\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a98d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # fit a multinomial logistic regression model on the training data\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the accuracy score of the model on the testing data\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # add the score to the list of cross-validation scores\n",
    "    scores.append(score)\n",
    "\n",
    "    # Print the k-fold index\n",
    "    print(f\"Fold: {len(scores)}/{k}: Accuracy: {score:.3f}\")\n",
    "    \n",
    "# compute the mean and standard deviation of the cross-validation scores\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "\n",
    "# print the mean and standard deviation of the cross-validation scores\n",
    "print(f\"Mean accuracy: {mean_score:.3f}, Standard deviation: {std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609fdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(KFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e71d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# create an instance of StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# create an empty list to store the cross-validation scores\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f77d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # fit a multinomial logistic regression model on the training data\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the accuracy score of the model on the testing data\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # add the score to the list of cross-validation scores\n",
    "    scores.append(score)\n",
    "\n",
    "    # Print the k-fold index\n",
    "    print(f\"Fold: {len(scores)}/{k}: Accuracy: {score:.3f}\")\n",
    "    \n",
    "# compute the mean and standard deviation of the cross-validation scores\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "\n",
    "# print the mean and standard deviation of the cross-validation scores\n",
    "print(f\"Mean accuracy: {mean_score:.3f}, Standard deviation: {std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98565b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(StratifiedKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61f6f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
     ]
    }
   ],
   "source": [
    "# define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# create an instance of StratifiedKFold\n",
    "skf = GroupKFold(n_splits=k)\n",
    "\n",
    "# create an empty list to store the cross-validation scores\n",
    "scores = []\n",
    "\n",
    "# groups\n",
    "groups = np.hstack([[ii] * 10 for ii in range(10)])\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb2e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each fold\n",
    "for train_index, test_index in skf.split(X, y, groups=groups):\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # fit a multinomial logistic regression model on the training data\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the accuracy score of the model on the testing data\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # add the score to the list of cross-validation scores\n",
    "    scores.append(score)\n",
    "\n",
    "    # Print the k-fold index\n",
    "    print(f\"Fold: {len(scores)}/{k}: Accuracy: {score:.3f}\")\n",
    "    \n",
    "# compute the mean and standard deviation of the cross-validation scores\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "\n",
    "# print the mean and standard deviation of the cross-validation scores\n",
    "print(f\"Mean accuracy: {mean_score:.3f}, Standard deviation: {std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0cb1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "gskf = StratifiedGroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "np.random.shuffle(y_)\n",
    "plot_cv(StratifiedGroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14246221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use tensorflow and work with the MNIST dataset\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "766d7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b67296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
     ]
    }
   ],
   "source": [
    "## examine the data\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1dcb3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
      "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
      "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
      "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
      "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
      "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
      "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
      "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
      "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
      "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
      "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
      "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
      "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
      "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
      "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0]], dtype=uint8)"
     ]
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cd6790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at some of the images\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a subplot 5x5 with random images\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for ax in axes:\n",
    "    img = random.choice(x_train)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc886124",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bc1f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bee28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Print the model summary\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7e1141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "088493c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/james/Projects/GitHub/DATA_340_NLP/Spring_2024/Lecture_Notebooks/wandb/run-20240326_141452-pedpwb9w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jam-tuck/mnist-classification/runs/pedpwb9w/workspace' target=\"_blank\">polar-snowball-1</a></strong> to <a href='https://wandb.ai/jam-tuck/mnist-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jam-tuck/mnist-classification' target=\"_blank\">https://wandb.ai/jam-tuck/mnist-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jam-tuck/mnist-classification/runs/pedpwb9w/workspace' target=\"_blank\">https://wandb.ai/jam-tuck/mnist-classification/runs/pedpwb9w/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log results in wandb\n",
    "WANDB_NOTEBOOK_NAME = \"mnist-classification\"\n",
    "\n",
    "wandb.init(project=\"mnist-classification\", config=hyperparams)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams[\"learning_rate\"])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    wandb.keras.WandbCallback(save_model=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd2c7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=hyperparams[\"batch_size\"],\n",
    "    epochs=hyperparams[\"epochs\"],\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "wandb.log({\"val_loss\": history.history[\"val_loss\"][-1], \"val_accuracy\": history.history[\"val_accuracy\"][-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8546a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40f9e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log results in wandb\n",
    "WANDB_NOTEBOOK_NAME = \"mnist-classification\"\n",
    "\n",
    "wandb.init(project=\"mnist-classification\", config=hyperparams)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams[\"learning_rate\"])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    wandb.keras.WandbCallback(save_model=False)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
