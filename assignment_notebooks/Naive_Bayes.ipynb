{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due date\n",
    "\n",
    "March 23, 2023\n",
    "\n",
    "N.B.: You are allowed to consult lecture notebooks, the kaggle competition, ChatGPT, and Stack Overflow. You are also permitted to work with one other student.\n",
    "\n",
    "## Assignment description\n",
    "\n",
    "\n",
    "Your task is to train a Naive Bayes model on the [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/data). The dataset contains 15,000 movie reviews. Your task is to train a Naive Bayes model on the training set and predict the labels of the test set. You will be evaluated on the methodologies you use to train the model and a comparison of your solutions. Your higest performing model will become your baseline model.\n",
    "\n",
    "### Data\n",
    "\n",
    "The dataset contains movie reviews from Rotten Tomatoes. Each review is labeled as follows:\n",
    "\n",
    "* 0 - negative\n",
    "* 1 - somewhat negative\n",
    "* 2 - neutral\n",
    "* 3 - somewhat positive\n",
    "* 4 - positive\n",
    "\n",
    "In addition to the entire review, the reviews are split into phrases and each phrase is labeled. The entire review is assigned a `SentenceID` and each phrase is assigned a `PhraseID`. The phrases were produced by the Stanford Parser (stanza). You are free to use the entire review or the phrases to train your model. In addition, you are free to create additional features from the data (such as Brown Tags). Finally, you are free to adjust the labels to negative, neutral, positive, if a classificaiton report demonstrates that a certain label is underperforming."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Exploration\n",
    "\n",
    "In the following section, please explore the data. You should explore the data to understand the following:\n",
    "\n",
    "* has the data been preprocessed already?\n",
    "* How many reviews are in the dataset?\n",
    "* How many phrases are in the dataset?\n",
    "* What is the distribution of the labels? (i.e. how many reviews are negative, neutral, positive)\n",
    "* What is the distribution of the labels for each phrase? (i.e. how many phrases are negative, neutral, positive)\n",
    "* What is the distribution of the words/tokens in the dataset?\n",
    "* How many unique words are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preprocessing\n",
    "\n",
    "In the following section, please preprocess the data. How you preprocess the data will align with what features you are engineering for your model. This might include: tokenization, lemmatization, stemming, removing stopwords, etc. You should also consider how you will handle the labels. You might consider the following: one-hot encoding, label encoding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you should engineer features for your model. You could consider the following: bag of words, tf-idf, brown tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Training\n",
    "\n",
    "In this section, you should engineer at least two models. You should train each model on the training set and evaluate the performance of each model on the test set. You should also compare the performance of each model. You should also explain the performance of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Model Evaluation\n",
    "\n",
    "In this section, you should evaluate the performance of your model. You should consider the following: accuracy, precision, recall, f1-score, confusion matrix, classification report, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Summary\n",
    "\n",
    "Please answer the following questions:\n",
    "    \n",
    "* What is the performance of your model?\n",
    "\n",
    "\n",
    "\n",
    "* What are the limitations of your model?\n",
    "\n",
    "\n",
    "\n",
    "* What are the strengths of your model?\n",
    "\n",
    "\n",
    "\n",
    "* What is the assumption of Naive Bayes? How does the assumption introduce bias into your model?\n",
    "\n",
    "\n",
    "\n",
    "* Why do you think Naive Bayes is a popular model?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
